Stanford researchers tested the most expensive legal AI tools on the market. Even Westlaw AI and Lexis+ AI fabricate information on 17–33% of queries. ChatGPT? Between 58% and 88%.

Here's the part that keeps me up at night: as these models get better at language, their hallucinations become *harder* to spot. GPT-3 hallucinated obviously. GPT-4 hallucinates eloquently — with fluent legal terminology, plausible-sounding article numbers, and conditions that pattern-match real tax law.

We call this the confidence-competence inversion: the better the language, the harder it becomes to distinguish knowledge from fabrication.

For Belgian tax professionals dealing with Art. 344 WIB, TOB classifications, and cross-regional inheritance rules, this isn't abstract. It's the difference between correct advice and a liability claim.

The cost of false certainty is always higher than the cost of honest uncertainty.

Full article: [link to blog post]

#FiscaleAI #BelgischRecht #TaxTech #AIHallucinations #Auryth
