# LinkedIn post — S02

You tried ChatGPT for a Belgian tax question. It was confident, articulate, and wrong.

So you closed the tab and told your colleagues: "AI can't handle tax work."

That was the right call — for that tool. But somewhere between "ChatGPT is unreliable" and "AI can't do tax work," a logical leap happened.

The data shows what's happening:
- AI adoption among tax professionals: 9% → 41% in one year (Wolters Kluwer)
- 59% still won't touch any AI tool
- Primary barrier: not cost — trust

The irony? The skeptics understand the problem better than anyone. They know tax work requires temporal precision, jurisdictional awareness, and source verification. Their standards are exactly right.

Their conclusion just happens to be wrong.

In the 1970s, UK tax inspectors were explicitly told: "under no circumstances were calculators to be used when performing tax calculations."

Nobody checks the calculator's math anymore. Not because it earned blind trust — but because it earned *appropriate* trust.

The question isn't whether you should trust AI blindly. Of course not. The question is whether you've tested whether the right tool, on the right tasks, produces verifiable results.

Full article: https://auryth.com/en/blog/ai-weerstand-fiscaal-advies-en/

#LegalTech #TaxTechnology #AI #TrustInAutomation #BelgianTax
