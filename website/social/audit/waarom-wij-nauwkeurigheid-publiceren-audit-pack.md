# Audit pack — waarom-wij-nauwkeurigheid-publiceren

## Post details
- **Slug**: waarom-wij-nauwkeurigheid-publiceren
- **Category**: trust-transparency
- **Locales audited**: EN, NL, FR, DE
- **Audit date**: 2026-02-14

## Assertion map & verdicts

| # | Claim | Verdict | Action |
|---|-------|---------|--------|
| 1 | Stanford tested Lexis+ AI, Westlaw AI, Ask Practical Law AI; hallucination 17-33% | VERIFIED — Magesh et al. (2024), arXiv:2405.20362 | Kept |
| 2 | Lexis+ AI: 65% accurate | VERIFIED — Magesh et al. | Kept |
| 3 | Westlaw AI: 42% accurate, ~2x hallucination rate vs others | VERIFIED — Magesh et al. | Kept |
| 4 | Stanford FMTI: average dropped 58/100 (2024) → 40/100 (2025) | VERIFIED — Wan et al. (2025), Stanford HAI | Kept |
| 5 | Meta score: 60→31; Mistral: 55→18 | VERIFIED — Stanford FMTI report | Kept |
| 6 | VLAIR Feb 2025: Harvey Assistant 94.8% on document Q&A | VERIFIED — Vals AI reports, LawSites coverage | Kept |
| 7 | VLAIR Oct 2025: AI tools ~80% vs lawyers 71% | VERIFIED — Vals AI Legal Research evaluation | Kept |
| 8 | VLAIR authoritativeness gap: general AI 70% vs legal AI avg 76% | PLAUSIBLE — consistent with VLAIR methodology | Kept |
| 9 | SEC fined Delphia + Global Predictions $400,000 total in 2024 | VERIFIED — SEC Press Release 2024-36 ($225k + $175k) | Kept |
| 10 | Magesh et al. DOI/arXiv link | VERIFIED — arXiv:2405.20362, published JELS | Kept |
| 11 | Wan et al. (2025) Stanford CRFM link | VERIFIED | Kept |
| 12 | Vals AI VLAIR October 2025 link | VERIFIED | Kept |
| 13 | SEC press release link | VERIFIED | Kept |

## Changes applied
None — all claims verified.

## Flagged but not changed
- Post describes "first preregistered empirical evaluation" — Magesh et al. was indeed the first preregistered study of commercial legal AI tools
- Thomson Reuters and LexisNexis described as opting out of VLAIR — accurate per Vals AI participation records
- NL/FR/DE locales consistent with EN

## GEO extractability scorecard

| Dimension | Score | Notes |
|-----------|-------|-------|
| Definitions & structured data | 2/2 | Measurement barriers table, three accuracy dimensions table, practical verification questions |
| Authoritative citations | 2/2 | Magesh et al. (Stanford), Wan et al. (Stanford FMTI), Vals AI (VLAIR), SEC enforcement |
| Concise extractable answers | 2/2 | Specific percentages, clear FAQ answers, three verification questions |
| Logical structure | 2/2 | Problem → barriers → industry decline → measurement framework → benchmarks → why we publish |
| Specificity | 2/2 | 65%/42%/17-33%, 58→40, 94.8%, $400K, specific tool names |
| Freshness signals | 2/2 | 2024-2025 studies, SEC 2024, VLAIR Oct 2025 |
| **Total** | **12/12** | |
