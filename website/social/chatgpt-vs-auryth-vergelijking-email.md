<!-- Email snippet for A01: ChatGPT vs Auryth -->
<!-- For: monthly digest / launch newsletter -->

**Subject:** We asked ChatGPT and Auryth the same Belgian tax questions — here's what happened
**Preview:** Three questions, two AI tools, one clear lesson about verifiability.

We ran a head-to-head experiment: three Belgian tax questions of increasing complexity, asked to both ChatGPT (GPT-4o) and Auryth TX on the same day.

The simple question — both got the number right. But only one cited Art. 215 WIB 92 and flagged the SME conditions. The temporal question — ChatGPT gave the current TOB rate for a 2021 question, missing the mid-year legislative change entirely. The complex question — ChatGPT identified 2 of 5 relevant tax domains for a TAK 23 product, missing gift/inheritance tax, TOB, and regional registration duties.

The pattern isn't about accuracy. It's about what we call the Verification Gap: the distance between an AI's stated confidence and your ability to independently check its claims. We built a Three-Layer Test (Source, Currency, Completeness) that any professional can apply before relying on AI-generated tax answers.

[Read the full experiment with sources and framework >>]
