**Subject:** Why the $800M legal AI bet doesn't work for Belgian tax

Harvey AI raised over $800 million and built their system on fine-tuning — training a model until the law is memorized in its weights. For US contract law, that makes sense.

For Belgian tax law, it doesn't.

Two major program laws per year. Three regions with diverging rules. A model trained in January is outdated by July.

We wrote a comparison of fine-tuning vs. RAG on the seven criteria that actually matter for tax professionals: source transparency, audit trails, catastrophic forgetting, Belgian suitability, and deployment cost.

The key insight: if your law changes faster than your model retrains, fine-tuning is the wrong architecture.

**[Read the full comparison →]**

---

*Auryth TX uses search-RAG fusion — not because fine-tuning is bad, but because Belgian tax law demands an architecture that can keep pace.*
