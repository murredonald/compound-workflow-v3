---
title: "\"Ik vertrouw AI niet voor fiscaal advies\" — en u hebt gelijk. Waarom u het toch zou moeten proberen."
description: "AI-scepsis in fiscaliteit is rationeel. De meeste tools verdienen het. Maar de hele categorie afwijzen omdat ChatGPT een verkeerd tarief hallucineert, is zoals rekenmachines weigeren omdat de eerste exemplaren vastliepen."
publishDate: 2026-02-15
author: "Auryth Team"
category: "strategy-decision"
category_name: "Strategie & beslissing"
tags: ["AI-adoptie", "professionele praktijk", "vertrouwen", "fiscale technologie", "veranderingsbeheer"]
locale: "nl"
draft: false
---

U probeerde ChatGPT voor een Belgische fiscale vraag. Het gaf u een zelfverzekerd antwoord met het verkeerde tarief, het verkeerde artikel, of een citaat dat niet bestaat. U sloot het tabblad, vertelde uw collega's dat het nutteloos is, en keerde terug naar Fisconetplus.

Dat was de juiste beslissing. Voor die tool.

Maar ergens tussen "ChatGPT is onbetrouwbaar" en "AI kan geen fiscaal werk doen," gebeurde een logische sprong die u nu meer kost dan u beseft.

## De ChatGPT-kater

Er speelt zich een patroon af in elk fiscaal kantoor in België. Een partner of senior medewerker test ChatGPT op een echte vraag — misschien het TOB-tarief voor kapitalisatiefondsen, misschien de successierechttarieven voor Brussel. Het antwoord komt zelfverzekerd en welbespraakt terug, en fout op manieren die echte schade zouden hebben veroorzaakt als het een cliënt had bereikt.

De professional trekt de voor de hand liggende conclusie: AI kan geen fiscaal werk aan. En vanuit die enkele ervaring wordt een hele technologiecategorie afgeschreven.

De data bevestigen dat dit wijdverspreid is. AI-adoptie onder fiscalisten en accountants verviervoudigde van 9% naar 41% tussen 2024 en 2025, volgens het Wolters Kluwer Future Ready Accountant Report. Maar dat betekent dat 59% nog steeds helemaal geen AI-tools gebruikt — en de voornaamste barrières zijn niet kosten of toegang. Het zijn vertrouwen en eerdere slechte ervaringen.

De ironie is dat de sceptici degenen zijn die het probleem het beste begrijpen. Zij weten dat fiscaal werk temporele precisie, jurisdictioneel bewustzijn en bronverificatie vereist. Zij weten dat een verkeerd tarief in een belastingaangifte geen kleine ongemak is — het is een beroepsaansprakelijkheidskwestie. Hun standaarden zijn exact juist. Hun conclusie is toevallig verkeerd.

## Wat u eigenlijk verwierp

Toen u "AI voor fiscaliteit" afwees, verwierp u een specifieke architectuur: een algemeen taalmodel zonder toegang tot actuele wetgeving, zonder begrip van Belgische jurisdicties, en zonder manier om zijn eigen output te verifiëren.

Dat is niet wat doelgebouwde juridische AI doet.

Het onderscheid is belangrijk op dezelfde manier als het belangrijk was in 2004 toen John D. Lee en Katrina See hun fundamentele onderzoek over vertrouwen in automatisering publiceerden. Zij identificeerden drie factoren die bepalen of professionals een tool vertrouwen: **prestatie** (werkt het betrouwbaar?), **proces** (kan ik begrijpen hoe het werkt?), en **doel** (werd het gebouwd voor mijn use case?).

ChatGPT faalt op alle drie voor fiscaal werk. Het hallucineert bronnen, zijn redenering is ondoorzichtig, en het werd gebouwd om te chatten — niet om Art. 344 §1 WIB 92 door drie lagen uitzonderingen te navigeren.

Maar het raamwerk van Lee en See beschrijft ook wat er gebeurt na een defect: vertrouwen daalt, en het herstelt — *als* het systeem betrouwbare prestatie toont over daaropvolgende interacties. Het probleem met de ChatGPT-kater is dat er geen daaropvolgende interacties zijn. Professionals probeerden één tool, trokken een conclusie op categorieniveau, en stopten met experimenteren.

## Het rekenmachine-precedent

Dit is niet de eerste keer dat een beroepsgroep een tool verwierp die uiteindelijk onmisbaar zou worden.

In de jaren 1970 vertelde de Britse Inland Revenue expliciet aan medewerkers dat "onder geen enkele omstandigheid rekenmachines mochten worden gebruikt bij het uitvoeren van belastingberekeningen." Van accountants werd verwacht dat zij de berekeningen met de hand deden. Door het decennium heen kregen nieuwe medewerkers bij accountantskantoren een bureau, een stoel en een telmachine — waarbij werkgevers hoogstens £50 bijdroegen aan een rekenmachine als de medewerker er een wilde.

In de jaren 1980 transformeerde technologie de accountancy, hoewel zoals één historicus opmerkte, "het misleidend zou zijn te zeggen dat het met enthousiasme werd omarmd" — het niveau van technologische expertise bij accountantskantoren nog in 1989 "was in een vreselijke staat."

Niemand controleert nog de wiskunde van de rekenmachine. Niet omdat rekenmachines blind vertrouwen verdienden, maar omdat zij *gepast* vertrouwen verdienden door consistente, verifieerbare prestatie bij taken die duidelijk binnen hun capaciteit lagen.

De vraag voor AI in fiscaliteit is niet of u het blindelings zou moeten vertrouwen. Natuurlijk niet. De vraag is of u heeft getest of de juiste tool, toegepast op de juiste taken, verifieerbare resultaten produceert die u tijd besparen.

## Het vertrouwensspectrum dat u negeert

Het onderzoek van Lee en See beschrijft drie posities op een vertrouwensspectrum:

- **Overmatig vertrouwen**: AI-output accepteren zonder verificatie. Dit is wat gebeurt wanneer iemand het antwoord van ChatGPT in een cliëntenmemo kopieert zonder de bronnen te controleren. Gevaarlijk — en precies wat sceptici vrezen.
- **Onvoldoende vertrouwen**: AI-tools volledig afwijzen op basis van één slechte ervaring. Dit is de ChatGPT-kater. Veilig op korte termijn, kostbaar op lange termijn.
- **Gepast vertrouwen**: AI gebruiken voor waarvoor het gebouwd is, verifiëren aan de grenzen, en professioneel oordeel handhaven over de conclusies.

Het grootste deel van het gesprek over AI in professionele dienstverlening zit vast in het debat tussen de eerste twee posities. De kantoren die beter zullen presteren zijn degenen die de derde vinden.

![Het vertrouwensspectrum: van overmatig vertrouwen via gepast vertrouwen naar onvoldoende vertrouwen](/blog/ai-weerstand-fiscaal-advies/trust-spectrum-nl-dark.png)

## Hoe gepast vertrouwen eruitziet in de praktijk

Gepast vertrouwen gaat niet over de AI geloven. Het gaat over de bronnen verifiëren die het u toont.

Wanneer een doelgebouwde fiscale onderzoekstool een antwoord geeft, toont het u welke wetsbepalingen het ophaalde, welke versie van de wet het toepaste, en uit welke jurisdictie het putte. U hoeft de interpretatie van de AI niet te vertrouwen — u leest de eigenlijke bronnen, op dezelfde manier als u de resultaten van een Fisconetplus-zoekopdracht zou lezen.

Het verschil is bereik en snelheid. Een handmatige Fisconetplus-zoekopdracht over een ETF-conversie kan de TOB-implicaties naar voren brengen en de Art. 19bis-invalshoek, de behandeling van roerende voorheffing en de rapportageverplichtingen missen. Niet omdat u onzorgvuldig bent, maar omdat cross-domein opvraging vereist dat u weet welke domeinen u moet doorzoeken — en niemand doorzoekt vijf databases wanneer zij denken dat zij het antwoord in de eerste hebben gevonden.

Doelgebouwde tools met domeintaxonomie doen die traversering systematisch. Zij markeren welke domeinen werden gedekt en welke niet. U neemt nog steeds de professionele oordelende beslissing. U neemt die alleen met bredere dekking dan handmatig onderzoek doorgaans bereikt.

## De competitieve wiskunde

Dit is waar scepsis stopt met beschermend te zijn en begint duur te worden.

Thomson Reuters rapporteert dat organisaties met strategische AI-adoptie 2x meer kans hebben op omzetgroei en 3,5x meer kans op kritieke operationele voordelen. Onder fiscale en accountantskantoren rapporteerde 83% van degenen die AI gebruikten verhoogde omzet in 2025, tegen 72% het jaar daarvoor.

Eén kantoor dat AI-tools voor belastingvoorbereiding gebruikt, rapporteerde 90% minder nalevingsfouten op jaarbasis en bereidde 55% meer aangiften per medewerker voor met vergelijkbare personeelsbezetting.

Dit zijn geen hypothetische projecties. Het zijn gemeten uitkomsten van kantoren die voorbij de ChatGPT-kater kwamen en tools vonden die gebouwd waren voor hun eigenlijke werk.

De competitieve kloof is nog niet dramatisch. Het zijn een paar uur hier, een gemiste bepaling daar. Maar het componeert. De kantoren die AI-ondersteund onderzoek doen, zijn niet alleen sneller — zij vinden bepalingen die handmatig onderzoek systematisch mist. Elke cross-domein vraag waar AI drie aanvullende relevante fiscale domeinen naar boven brengt, is een vraag waar het niet-AI-kantoor smaller advies leverde zonder het te weten.

En 76% van de accountancyafgestudeerden zegt dat zij meer geneigd zijn om zich bij kantoren aan te sluiten die actief AI gebruiken. De talentpijplijn prijst de technologiekloof al in.

## Het pragmatische pad

U hoeft niet van gedachten te veranderen over AI. U moet één tool testen op twintig vragen en de resultaten zelf controleren.

Niet ChatGPT. Geen algemene assistent. Een tool gebouwd voor Belgische fiscaliteit, met broncitaten, temporele versioning en jurisdictionele tagging.

Stel het de vragen waarvan u de antwoorden al kent. Controleer elke bron die het citeert. Verifieer elk artikelnummer. Tel hoe vaak het juist is, hoe vaak het fout is, en hoe vaak het een bepaling naar boven brengt die u niet had overwogen.

Als het uw test niet doorstaat, hebt u een uur verloren. Als het slaagt, hebt u een onderzoeksversneller gevonden die uw expertise grondiger maakt, niet minder relevant.

De professionals die als eerste adopteren, vervangen hun oordeel niet. Zij vergroten hun bereik. En de kloof tussen kantoren die onderzoek doen over vijf fiscale domeinen en kantoren die onderzoek doen over twee, zal alleen maar groeien vanaf hier.

---

## Gerelateerde artikels

- [5 Belgische fiscale vragen waar generieke AI gegarandeerd faalt](/nl/blog/5-vragen-generieke-ai-faalt-nl/)
- [Waarom transparantie belangrijker is dan nauwkeurigheid in juridische AI](/nl/blog/transparantie-vs-nauwkeurigheid-nl/)
- [Hoe een juridische AI-tool evalueren: 10 vragen die er echt toe doen](/nl/blog/juridische-ai-tool-evalueren-nl/)
- [AI-hallucinaties: waarom ChatGPT bronnen verzint (en hoe u het herkent)](/nl/blog/ai-hallucinaties-fiscaal-nl/)

---

## Hoe Auryth TX het vertrouwensprobleem aanpakt

Auryth TX werd gebouwd door fiscalisten die elke zorg in dit artikel delen. Wij bouwden geen chatbot en voegden fiscale data toe. Wij bouwden een onderzoekstool en voegden AI toe.

Elk antwoord toont de wetsbepalingen die het ophaalde, de versie van de wet die het toepaste, en de jurisdictie waaruit het putte. [Confidence scoring](/nl/glossary/confidence-scoring/) vertelt u hoeveel van het relevante [corpus](/nl/glossary/corpus/) werd gedekt — niet alleen of het model zich zeker voelt. Wanneer het systeem niet zeker is, zegt het dat.

U hoeft de AI niet te vertrouwen. U verifieert de bronnen die het u toont — op dezelfde manier als u elke onderzoekstool verifieert. Het verschil is dat deze zoekt over vijf fiscale domeinen wanneer u normaal over twee zou zoeken.

De sceptici hadden gelijk om sceptisch te zijn. Wij bouwden voor hen.

[Test het op uw moeilijkste vragen — sluit u aan bij de wachtlijst →](/nl/waitlist/)

---

*Bronnen:*
*1. Wolters Kluwer, [Future Ready Accountant Report](https://www.wolterskluwer.com/en/news/wolters-kluwer-releases-its-2025-future-ready-accountant-report) (2025). AI-adoptie onder fiscalisten 9% → 41%.*
*2. Lee, J.D. & See, K.A. (2004). "[Trust in Automation: Designing for Appropriate Reliance](https://doi.org/10.1518/hfes.46.1.50_30392)." Human Factors, 46(1), 50-80.*
*3. Thomson Reuters, Future of Professionals Report (2025). Strategische AI-adoptie en omzetcorrelatie.*
*4. Bridgewater State University, "How Technology Has Changed the Field of Accounting" — data over rekenmachineweerstand in de jaren 1970.*
*5. [ITAA](https://www.itaa.be/en/) — Belgisch Instituut voor Belastingadviseurs en Accountants. 16.000+ leden, verplichte beroepsaansprakelijkheidsverzekering.*
