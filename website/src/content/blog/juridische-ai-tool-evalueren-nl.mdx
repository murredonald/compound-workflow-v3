---
title: "Hoe evalueert u een juridische AI-tool? 10 vragen die er écht toe doen"
description: "De meeste kantoren beginnen met 'hoe nauwkeurig is het?' Dat is vraag 10 op deze lijst. Hier zijn de negen vragen die u eerst moet stellen — en waarom ze meer uitmaken voor professioneel fiscaal werk."
publishDate: 2026-02-14
author: "Auryth Team"
category: "strategy-decision"
category_name: "Strategie & beslissing"
tags: ["AI-evaluatie", "juridische AI", "belastingtechnologie", "due diligence", "beroepsaansprakelijkheid"]
locale: "nl"
draft: false
---

De eerste vraag die de meeste kantoren stellen bij het evalueren van een juridische AI-tool is "hoe nauwkeurig is het?" Het klinkt redelijk. Het is ook de minst nuttige vraag op deze lijst.

Nauwkeurigheid zonder transparantie is een aansprakelijkheidsrisico. Een tool die 95% nauwkeurig is maar u niet kan tonen welke 5% fout is, is gevaarlijker dan een tool die 90% nauwkeurig is en bij elk antwoord de bronnen toont. U kunt een gekend risico beheren. Een verborgen risico niet.

Deze checklist werkt voor elke juridische AI-tool — Auryth, een concurrent, of een algemeen model dat uw medewerkers al in het geheim gebruiken. Als een leverancier deze vragen niet duidelijk kan beantwoorden, zegt dat u iets. Als ze het wel kunnen, verifieer dan de antwoorden.

## 1. Waar komen de bronnen vandaan?

**Wat u moet vragen:** Bevraagt de tool een samengesteld juridisch [corpus](/nl/glossary/corpus/), of doorzoekt hij het open internet? Wie beheert het corpus? Hoe is het gestructureerd?

**Waarom het uitmaakt:** Een tool die het internet doorzoekt, vindt blogposts, verouderde wetgeving en buitenlandse jurisdicties vermengd met het actuele recht. Een tool met een samengesteld corpus — WIB 92, VCF, Fisconetplus, DVB-voorafgaande beslissingen, rechtspraak — heeft een gedefinieerde kennisgrens. U weet wat hij kan doorzoeken en wat niet.

**Rode vlag:** "We gebruiken de grootste dataset beschikbaar" zonder specificatie van de inhoud. Grootte is geen kwaliteit. Een corpus van 10 miljoen ongestructureerde webpagina's is slechter dan 50.000 zorgvuldig gestructureerde juridische documenten met metadata.

## 2. Kunt u elke citatie verifiëren?

**Wat u moet vragen:** Wanneer de tool een bron citeert, kunt u dan doorklikken naar het originele document? Is de [citatie](/nl/glossary/citation/) verifieerbaar, of is het gewoon een referentiestring die het model heeft gegenereerd?

**Waarom het uitmaakt:** Stanford-onderzoekers ontdekten dat zelfs toegewijde juridische AI-tools — Westlaw AI, Lexis+ AI — hallucinerenbij 17–33% van de zoekopdrachten. De [hallucinaties](/nl/glossary/hallucination/) zijn geen willekeurige rommel. Het zijn plausibel klinkende citaties naar bepalingen die niet zeggen wat het model beweert. De enige verdediging is verificatie.

**Rode vlag:** Citaties zonder klikbare links naar de originele tekst. Als u een citatie niet binnen 30 seconden kunt verifiëren, is het geen citatie — het is een suggestie.

## 3. Weet hij wanneer hij het niet weet?

**Wat u moet vragen:** Biedt de tool betrouwbaarheidsscores aan? Wanneer bewijs dun gezaaid of afwezig is, vertelt hij u dat dan expliciet — of antwoordt hij met hetzelfde vertrouwen ongeacht de situatie?

**Waarom het uitmaakt:** In professionele fiscale praktijk is weten dat er geen gezag bestaat over een specifiek punt waardevolle informatie. Het betekent dat u in interpretatiegebied bent en dienovereenkomstig moet handelen. Een tool die altijd met uniform vertrouwen antwoordt — of het nu ondersteund wordt door drie arresten van het Hof van Cassatie of door helemaal niets — traint u om te stoppen met letten op zekerheid.

**Rode vlag:** Elk antwoord geleverd met dezelfde gezaghebbende toon, ongeacht de sterkte van het onderliggende bewijs.

## 4. Hoe actueel is de kennisbasis?

**Wat u moet vragen:** Wanneer de wet verandert, hoe snel wordt de tool bijgewerkt? Wordt hij bijgewerkt binnen uren, dagen, weken of maanden? Wanneer was de laatste update?

**Waarom het uitmaakt:** Het Belgische belastingrecht verandert voortdurend. Twee grote programmawetten per jaar. Regionale divergentie over Vlaanderen, Wallonië en Brussel. De programmawet van juli 2025 herstructureerde het regime van investeringsaftrek. Als een tool nog steeds de regels van vóór juli weergeeft, is hij niet alleen verouderd — hij heeft zelfverzekerd ongelijk over het huidige recht.

**Rode vlag:** Vage antwoorden zoals "regelmatig bijgewerkt" zonder een specifieke updatefrequentie. Vraag naar de datum van de laatste corpusupdate. Als ze u dat niet kunnen vertellen, is dat uw antwoord.

## 5. Begrijpt hij de juridische hiërarchie?

**Wat u moet vragen:** Wanneer de tool meerdere bronnen ophaalt, rangschikt hij ze dan op juridisch gezag? Weegt een arrest van het Hof van Cassatie zwaarder dan een Fisconetplus-circulaire? Weegt een grondwettelijke bepaling zwaarder dan een ministerieel besluit?

**Waarom het uitmaakt:** Juridische hiërarchie is geen leuk-om-te-hebben — het is hoe juridisch redeneren werkt. Een Fisconetplus-circulaire die in strijd is met rechtspraak is de circulaire die fout is, niet de rechtspraak. Een tool die alle bronnen als gelijk gewogen tekstbrokken behandelt, zal af en toe het verkeerde gezag als het primaire antwoord naar voren brengen.

**Rode vlag:** Platte zoekresultaten zonder indicatie van bronautoriteit of juridisch gewicht.

## 6. Kan hij temporele vragen aan?

**Wat u moet vragen:** Als u vraagt over een transactie in 2019, haalt de tool dan het recht van 2019 of het huidige recht op? Kan hij onderscheid maken tussen temporele versies van dezelfde bepaling?

**Waarom het uitmaakt:** Het Belgische tarief vennootschapsbelasting was 29,58% in 2019 en 25% vandaag. Beide zijn correct — voor verschillende aanslagjaren. Een tool zonder temporele versioning zal welke versie zijn zoekopdracht het eerst naar boven haalt ophalen. Voor een belastingadviseur die over een historische periode adviseert, is dat geen klein ongemak — het is een aansprakelijkheidsrisico.

**Rode vlag:** Geen mogelijkheid om een referentiedatum te specificeren. Als de tool geen onderscheid kan maken tussen "wat was de wet in 2019?" en "wat is de wet vandaag?", faalt hij deze test.

## 7. Hoe worden uw gegevens behandeld?

**Wat u moet vragen:** Waar worden klantgegevens opgeslagen? Worden ze gebruikt om het model te trainen? Wie heeft toegang? Voldoet de tool aan GDPR-artikel 22 over geautomatiseerde besluitvorming? Wat gebeurt er met uw zoekopdrachten nadat de sessie is beëindigd?

**Waarom het uitmaakt:** 56% van de advocatenkantoren noemt gegevensprivacy als hun belangrijkste zorg bij het evalueren van AI-tools. Professionele vertrouwelijkheid is niet optioneel — het is een wettelijke verplichting. Als klantzoekopdrachten worden gebruikt om het model te verbeteren, zitten de gegevens van uw klant in de trainingsset. Als de gegevens de EU verlaten zonder adequate waarborgen, heeft u een GDPR-nalevingsprobleem.

**Rode vlag:** Servicevoorwaarden die de leverancier brede rechten geven om "invoergegevens" te gebruiken voor "serviceverbetering". Lees de gegevensverwerkingsovereenkomst. Als die er niet is, loop weg.

## 8. Wat gebeurt er wanneer hij fout is?

**Wat u moet vragen:** Bewaart de tool een audittrail? Kunt u reconstrueren welke bronnen werden opgehaald, wat werd verworpen en hoe het antwoord werd gegenereerd? Welke disclaimers of aansprakelijkheidsbeperkingen zijn van toepassing?

**Waarom het uitmaakt:** Professionele aansprakelijkheid in de Belgische belastingpraktijk verdwijnt niet omdat u een tool hebt gebruikt. Ordes van advocaten over heel Europa convergeren naar een duidelijk principe: AI kan onafhankelijk onderzoek, analyse en oordeel niet vervangen. Wanneer een tool fout advies geeft en u het aan een klant doorgeeft, moet u uw verificatieproces kunnen aantonen. Een audittrail maakt dat mogelijk. Een chattranscriptie niet.

**Rode vlag:** Geen logging, geen audittrail, geen mogelijkheid om eerdere zoekopdrachten te bekijken. Als u uw onderzoeksproces niet kunt reconstrueren, kunt u het niet verdedigen.

## 9. Kunt u exporteren voor professioneel gebruik?

**Wat u moet vragen:** Kunt u resultaten exporteren in een gestructureerd formaat geschikt voor professionele documentatie — citaties geformatteerd, bronnen gelinkt, betrouwbaarheid genoteerd? Of bent u beperkt tot het kopiëren van chattekst?

**Waarom het uitmaakt:** Een tool die gestructureerd, exporteerbaar onderzoek produceert, versnelt uw workflow. Een tool die chatachtige tekst produceert, creëert een opmaakstap tussen onderzoek en werkproduct. Het verschil tussen deze twee is het verschil tussen een onderzoekstool en een chatbot.

**Rode vlag:** Output beperkt tot ongeformatteerde tekst in een chatvenster, zonder export- of integratieopties.

## 10. Publiceert hij nauwkeurigheidsmetrieken?

**Wat u moet vragen:** Wat is het gemeten hallucinatiepercentage van de tool? Wie heeft het gemeten — de leverancier of een onafhankelijke partij? Zijn de metrieken gepubliceerd, of moet u hun woord ervoor nemen?

**Waarom het uitmaakt:** Dit staat om een reden als laatste op de lijst. Nauwkeurigheid is belangrijk, maar het is de metriek waar leveranciers voor optimaliseren in marketing en de metriek waar professionals te veel nadruk op leggen bij het evalueren. Een tool die 95% nauwkeurig en ondoorzichtig is, is gevaarlijker dan een tool die 90% nauwkeurig en transparant is — omdat u de 10% kunt verifiëren en corrigeren, maar u de 5% niet kunt identificeren.

**Rode vlag:** "99% nauwkeurigheid"-claims zonder gepubliceerde methodologie, testsets of onafhankelijke validatie. Als de leverancier zijn eigen nauwkeurigheid heeft gemeten, vraag dan hoe. Als ze de methodologie niet kunnen uitleggen, is het getal marketing.

![Tien vragen voor het evalueren van een juridische AI-tool — gescoorde checklist voor belastingadviseurs](/blog/juridische-ai-tool-evalueren/evaluation-checklist-nl-dark.png)

---

## De ongemakkelijke waarheid

Slechts 26% van de advocatenkantoren heeft AI actief geïntegreerd vanaf 2025. Maar 31% van de individuele advocaten gebruikt al generatieve AI op het werk — velen zonder medeweten of goedkeuring van hun kantoor. De vraag is niet of uw kantoor AI zal gebruiken. Het is of u een tool zult kiezen die aan professionele normen voldoet, of dat uw medewerkers ChatGPT in een browsertabblad blijven gebruiken en op het beste hopen.

Deze tien vragen geven u een kader voor het eerste. Print ze af. Gebruik ze in uw volgende leveranciersvergadering. Gebruik ze om de tools te evalueren die uw team al gebruikt. De antwoorden zullen u alles vertellen wat u moet weten.

---

## Gerelateerde artikels

- [Wat is RAG — en waarom het op zich niet genoeg is voor juridische AI](/nl/blog/wat-is-rag-nl/)
- [Fine-tuning vs. RAG: twee manieren om AI slim te maken — en waarom het uitmaakt welke uw belastingtool heeft gekozen](/nl/blog/fine-tuning-vs-rag-nl/)
- [Waarom transparantie meer uitmaakt dan nauwkeurigheid in juridische AI](/nl/blog/transparantie-vs-nauwkeurigheid-nl/)

---

## Hoe Auryth TX scoort op deze 10 vragen

We hebben Auryth TX gebouwd om elke vraag op deze lijst te beantwoorden. Niet omdat we de lijst hebben geschreven — maar omdat dit de vragen zijn die elke professional zou moeten stellen, en we willen liever dat u ze stelt dan niet.

1. **Bronnen:** Belgisch juridisch corpus — WIB 92, VCF, Fisconetplus, DVB-voorafgaande beslissingen, rechtspraak, doctrinaire publicaties — allemaal samengesteld en gestructureerd.
2. **Citatieverificatie:** Elke citatie linkt naar de originele bron. Elke claim wordt onafhankelijk gevalideerd na generatie.
3. **Onzekerheid:** Betrouwbaarheidsscore per claim. Wanneer bewijs dun gezaaid is, vertellen we u dat expliciet.
4. **Actualiteit:** Corpus bijgewerkt binnen uren na juridische wijzigingen. De programmawet van juli 2025 was dezelfde dag doorzoekbaar.
5. **Juridische hiërarchie:** 13-niveaus autoriteitranking over het Belgische rechtssysteem — Grondwet tot doctrine.
6. **Temporele zoekopdrachten:** Point-in-time ophaling met temporele metadata op elke bepaling.
7. **Gegevensverwerking:** EU-gegevensresidentie. Geen training op klantzoekopdrachten. Volledige GDPR-naleving met gepubliceerde verwerkersovereenkomst.
8. **Audittrail:** Elke zoekopdracht gelogd met opgehaalde bronnen, verworp bronnen, betrouwbaarheidsscores en generatiemetadata.
9. **Export:** Gestructureerde output met geformatteerde citaties, autoriteitgewichten en betrouwbaarheidsindicatoren.
10. **Nauwkeurigheid:** Gepubliceerde methodologie. Onafhankelijke validatie. En transparant genoeg dat u elk antwoord zelf kunt verifiëren.

[Test deze 10 vragen op een echte Belgische belastingvraag — sluit u aan bij de wachtlijst →](/nl/waitlist/)

---

*Bronnen:*
*1. Magesh, V. et al. (2025). "[Hallucination-Free? Assessing the Reliability of Leading AI Legal Research Tools](https://arxiv.org/abs/2405.20362)." Journal of Empirical Legal Studies.*
*2. AffiniPay (2025). [Legal Industry Report: AI Adoption in Law Firms](https://www.mycase.com/blog/ai/ai-adoption-in-law-firms/).*
*3. Bar Council of England and Wales (2025). "[Considerations when using ChatGPT and generative artificial intelligence](https://www.barcouncil.org.uk/resource/updated-guidance-on-generative-ai-for-the-bar.html)." Bijgewerkt november 2025.*
*4. Thomson Reuters Institute (2025). "Generative AI in Professional Services."*
