---
title: "Warum wir keinen Chatbot bauen"
description: "Chat-Interfaces wirken modern, produzieren aber ephemere, nicht vertretbare Ergebnisse. Professionelle Steuerforschung braucht strukturierte Antworten, die Sie ablegen, reproduzieren und verteidigen können."
publishDate: 2026-02-17
author: "Auryth Team"
category: "strategy-decision"
category_name: "Strategie & Entscheidung"
tags: ["Chatbot vs. Recherchetool", "Rechts-KI", "strukturierte Ausgabe", "professioneller Workflow", "Steuertechnologie"]
locale: "de"
draft: false
---

Ihr Mandant ruft an. Er möchte wissen, wie Sie zu der Quellensteuerposition gelangt sind, die Sie vor sechs Wochen empfohlen haben. Sie öffnen Ihr KI-Tool — und scrollen durch einen Chat-Verlauf, der sich wie ein Bewusstseinsstrom liest. Irgendwo zwischen einer Mehrwertsteuerfrage und einem Thread zur Unternehmensumstrukturierung liegt der relevante Austausch begraben. Vielleicht. Falls die Sitzung nicht gelöscht wurde.

Das ist kein Sonderfall. Das ist die Standarderfahrung jedes Profis, der einen Chatbot für ernsthafte Recherche nutzt.

## Das Chatbot-Paradigma hat ein strukturelles Problem

Die gesamte Legal-AI-Branche konvergierte auf Chat. ChatGPT trainierte Hunderte Millionen Nutzer darauf, ein Textfeld und eine Konversation zu erwarten. Jeder Wettbewerber folgte. Das Ergebnis: professionelle Steuerrecherche, gezwängt in eine Oberfläche, die für beiläufige Konversation konzipiert wurde.

Das Problem ist nicht die Genauigkeit — obwohl auch das wichtig ist. Das Problem ist **Vergänglichkeit**. Chat-Konversationen sind:

- **Unstrukturiert.** Die Antwort ist über mehrere Austausche verteilt, vermischt mit Ihren Nachfragen und den Absicherungen der KI
- **Nicht reproduzierbar.** Stellen Sie morgen dieselbe Frage und erhalten Sie eine andere Antwort — ohne Möglichkeit zum Vergleich
- **Nicht exportierbar.** Versuchen Sie, ein Chat-Protokoll in ein Mandantenmemo zu verwandeln. Sie werden alles von Grund auf neu schreiben
- **Nicht vertretbar.** Wenn ein Kollege, eine Aufsichtsbehörde oder ein Mandant fragt „Wie sind Sie zu diesem Schluss gelangt?" — ein Chat-Protokoll ist keine Antwort

Seit Mitte 2023 wurden weltweit Hunderte Fälle von KI-generierten rechtlichen Halluzinationen dokumentiert, davon mehr als 50 allein im Juli 2025 mit erfundenen Zitaten. Die meisten betrafen Profis, die Chat-Ausgaben als Recherche behandelten. Das war es nicht.

## Der Rechenschaftstest

Bevor Sie sich bei professioneller Arbeit auf ein KI-Tool verlassen, stellen Sie drei Fragen:

| Frage | Chat-KI | Rechercheplattform |
|-------|---------|-------------------|
| **Kann ich dieses Ergebnis nächste Woche reproduzieren?** | Nein — andere Sitzung, andere Antwort | Ja — dieselbe Anfrage, dieselbe strukturierte Ausgabe |
| **Kann ich das als Mandantenlieferung exportieren?** | Ein Konversationsprotokoll kopieren? | Strukturierte Ausgabe mit Quellenangaben, bereit zum Ablegen |
| **Kann ich das verteidigen, falls angefochten?** | „Die KI sagte es mir in einem Chat" | Dokumentierte Recherche mit Quellenkette und Konfidenzindikatoren |

Wenn die Antwort auf eine dieser Fragen nein lautet, machen Sie keine Recherche. Sie führen eine Konversation.

> Was Sie nicht reproduzieren können, können Sie nicht verteidigen.

## Warum Chat funktioniert — und wo es aufhört

Um fair zu sein: Chat-Interfaces sind nicht nutzlos. Sie funktionieren gut für Aufgaben mit niedrigem Risiko, bei denen Rechenschaftspflicht keine Rolle spielt. Mandantenaufnahme auf einer Website, Brainstorming-Notizen, Entwurf einer ersten E-Mail — Chat ist in Ordnung.

Das Scheitern tritt ein, wenn die Anforderungen steigen. Wenn ein belgischer Steuerberater sich auf eine KI-Antwort für einen Antrag an den Dienst Voorafgaande Beslissingen (DVB, belgischer Vorabentscheidungsdienst) verlässt, muss diese Antwort auf spezifische Rechtsquellen zurückführbar sein. Wenn ein Buchhalter eine Position für ein ITAA-Peer-Review vorbereitet, muss die Recherche reproduzierbar sein. Wenn ein Notar eine Nachlassplanung strukturiert, muss die Analyse als formelles Memo exportierbar sein.

Chat kann nichts davon leisten. Nicht weil das zugrundeliegende Modell schlecht ist, sondern weil die Oberfläche strukturell unfähig ist, vertretbare Arbeitsprodukte zu erzeugen.

## Die belgische regulatorische Realität

Die Orde van Vlaamse Balies (OVB, die flämische Anwaltskammer) veröffentlichte detaillierte KI-Richtlinien, die von Profis verlangen, ihre KI-Tool-Nutzung zu dokumentieren, Quellenrückverfolgbarkeit aufrechtzuerhalten und nachzuweisen, dass ihre KI-unterstützte Arbeit rechtlich und ethisch einwandfrei ist. Die belgische Datenschutzbehörde folgte im September 2024 mit umfassenden Leitlinien zu KI-Systemen und DSGVO-Konformität.

Der [EU AI Act](/de/glossary/eu-ai-act/), ab August 2026 vollständig anwendbar, verlangt automatische strukturierte Protokollierung für Hochrisiko-KI-Systeme gemäß Artikel 12. Ein Chat-Protokoll qualifiziert nicht als strukturierte Protokollierung.

Währenddessen reagieren Versicherer auf KI-Risiken mit nahezu absoluten Ausschlüssen. Berufshaftpflichtpolicen schließen zunehmend Deckung für Ansprüche aus, die „in irgendeiner Weise mit KI zusammenhängen" — was bedeutet: Wenn Ihre KI-unterstützte Beratung schiefgeht und Ihre Dokumentation ein Chat-Verlauf ist, kann Ihr Versicherer den Anspruch vollständig ablehnen.

Die regulatorische Richtung ist klar: **Prüfbarkeit ist nicht optional**. Jedes in der Berufspraxis eingesetzte Tool muss Ergebnisse produzieren, die überprüft, reproduziert und verteidigt werden können. Chat-Architekturen wurden nie dafür konzipiert.

## Was wir stattdessen bauen: aktenfeste Recherche

**Aktenfeste KI** — *dossiervaste AI* — bedeutet, dass jede vom System produzierte Antwort als professionelles Arbeitsprodukt abgelegt, exportiert und verteidigt werden kann. Keine Konversation. Ein strukturiertes Rechercheergebnis.

![Chat-KI versus Rechercheplattform: von ephemerem Chat zu vertretbarer Ausgabe](/blog/waarom-geen-chatbot/chat-vs-research-platform-de-dark.png)

Der Unterschied ist architektonisch, nicht kosmetisch:

| Aspekt | Chat-Paradigma | Aktenfeste Recherche |
|--------|--------------|----------------------|
| **Ausgabeformat** | Freitext-Konversation | Strukturierte Karte: Schlussfolgerung, Quellen, Ausnahmen, Konfidenz, Lücken |
| **Quellenkette** | Inline-Erwähnungen, falls vorhanden | Jede Behauptung verknüpft mit einer spezifischen Bestimmung, rangiert nach Rechtsautorität |
| **Reproduzierbarkeit** | Neue Sitzung = neue Antwort | Dieselbe Anfrage produziert dasselbe strukturierte Ergebnis, versioniert über Zeit |
| **Export** | Kopieren eines Chat-Protokolls | PDF mit Quellenanhang, bereit für Mandantenakte |
| **Organisation** | Flacher Chat-Verlauf | Mandantenordner, durchsuchbares Recherchearchiv |
| **Konfidenz** | Die KI klingt bei allem gleich sicher | Explizite Konfidenzindikatoren — das System sagt Ihnen, wann es unsicher ist |

Das ist keine Feature-Präferenz. Es ist der Unterschied zwischen einem Tool, das Ihnen beim Brainstorming hilft, und einem Tool, das Sie bei der Berufsausübung unterstützt.

## Die Branche weiß bereits, dass Chat nicht ausreicht

Der definierende Wandel der Legal-Tech-Branche im Jahr 2025 war der Übergang von Chatbot-artiger KI zu agentischen, eingebetteten Systemen. Thomson Reuters, LexisNexis und Harvey fügten alle auf der ILTACON 2025 agentische und workflow-integrierte Funktionen neben ihren Chat-Interfaces hinzu. Branchenanalysten prognostizieren, dass KI-Systeme zunehmend strukturierte Interfaces statt leerer Textfelder bereitstellen werden.

Die Frage ist nicht, ob die Branche über Chat hinausgeht. Die Frage ist, ob Ihre Kanzlei sich bewegt, bevor ein Berufshaftungsvorfall die Sache erzwingt.

Ein erheblicher Anteil der professionellen Dienstleistungszeit wird mit der Suche nach Antworten verschwendet, die über unstrukturierte Wissenssysteme verstreut sind. Chat-Verläufe verschlimmern das, statt es zu verbessern. Jede unbeantwortete Frage nach „Was sagte die KI zu diesem Fall vor drei Monaten?" repräsentiert institutionelles Wissen, das generiert und sofort verloren wurde.

---

## Verwandte Artikel

- [Was ist Autoritätsrangierung — und warum Ihr Rechts-KI-Tool sie wahrscheinlich ignoriert →](/blog/authority-ranking-juridische-ai-de)
- [Was ist Konfidenzwertung — und warum sie ehrlicher ist als eine selbstsichere Antwort →](/blog/confidence-scoring-uitgelegd-de)
- [Wie Sie ein Rechts-KI-Tool bewerten: 10 Fragen, die wirklich zählen →](/blog/juridische-ai-tool-evalueren-de)

---

## Wie Auryth TX das umsetzt

Jede von Auryth TX produzierte Antwort folgt derselben Struktur: eine klare Schlussfolgerung, eine rangierte Quellenkette gewichtet nach Rechtsautorität, eine Ausnahmenkarte, die bereichsübergreifende Risiken markiert, Konfidenzindikatoren, die zeigen, wo das System sicher ist und wo nicht, und explizite Lückenerkennung, die identifiziert, was das System nicht finden konnte.

Die Ausgabe ist für Ihre Mandantenakte konzipiert, nicht für Ihren Chat-Verlauf. Export als PDF mit vollständigem Quellenanhang. Organisieren Sie Recherchen nach Mandant, nach Angelegenheit, nach Frage. Kehren Sie Monate später zu einer Anfrage zurück und erhalten Sie dasselbe strukturierte Ergebnis — aktualisiert, falls sich das zugrundeliegende Recht geändert hat.

Wir haben keinen Chatbot mit besseren Fußnoten gebaut. Wir haben eine Rechercheplattform gebaut, bei der jede Antwort von Design her vertretbar ist.

*Nie wieder auf Basis veralteter Recherche beraten — wir warnen Sie automatisch, wenn sich Quellen ändern.*

---

*Quellen:*
*1. Charlotin, D. (2025). "[AI Hallucination Cases Database](https://www.damiencharlotin.com/hallucinations/)." HEC Paris.*
*2. Dahl, M. et al. (2024). "[Large Legal Fictions: Profiling Legal Hallucinations in Large Language Models](https://arxiv.org/abs/2401.01301)." Journal of Legal Analysis, 16(1), 64-93.*
*3. Orde van Vlaamse Balies (2024). "AI-richtlijnen voor advocaten."*
*4. Belgische Datenschutzbehörde (2024). "[Informationsbroschüre: KI-Systeme und DSGVO](https://www.dataprotectionauthority.be/citizen/artificial-intelligence)." September 2024.*
*5. EU-Verordnung 2024/1689 (AI Act), Artikel 12: Anforderungen an automatische Protokollierung für Hochrisiko-KI-Systeme.*
