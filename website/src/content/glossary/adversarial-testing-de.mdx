---
term: "Adversariales Testen"
termSlug: "adversarial-testing"
short: "Systematisches Angreifen von Modellen mit schwierigen oder bösartigen Eingaben, um Schwachstellen aufzudecken."
category: "ai-ml"
category_name: "KI & Machine Learning"
related: ["stress-testing", "jailbreaking", "model-robustness"]
synonyms: ["Red Teaming", "Adversarielle Evaluation"]
locale: "de"
draft: false
---

## Definition

Adversariales Testen konfrontiert KI-Systeme mit herausfordernden oder absichtlich schädlichen Inputs, um Verwundbarkeiten vor dem Einsatz zu finden.

## References

> Alexey Kurakin et al. (2016), "[Adversarial Machine Learning at Scale](https://arxiv.org/abs/1611.01236)", International Conference on Learning Representations.

> Florian Tramèr et al. (2017), "[Ensemble Adversarial Training: Attacks and Defenses](https://doi.org/10.48550/arxiv.1705.07204)", arXiv.

> Nicholas Carlini et al. (2017), "[Towards Evaluating the Robustness of Neural Networks](https://doi.org/10.1109/sp.2017.49)", .
