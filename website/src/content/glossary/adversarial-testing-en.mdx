---
term: "Adversarial testing"
termSlug: "adversarial-testing"
short: "Systematically probing models with difficult or malicious inputs to find failures."
category: "ai-ml"
category_name: "AI & Machine Learning"
related: ["stress-testing", "jailbreaking", "model-robustness"]
synonyms: ["Red teaming", "Adversarial evaluation"]
locale: "en"
draft: false
---

## Definition

Adversarial testing exposes AI systems to challenging, out-of-distribution, or intentionally harmful inputs to uncover vulnerabilities and failure modes before deployment.

## References

> Alexey Kurakin et al. (2016), "[Adversarial Machine Learning at Scale](https://arxiv.org/abs/1611.01236)", International Conference on Learning Representations.

> Florian TramÃ¨r et al. (2017), "[Ensemble Adversarial Training: Attacks and Defenses](https://doi.org/10.48550/arxiv.1705.07204)", arXiv.

> Nicholas Carlini et al. (2017), "[Towards Evaluating the Robustness of Neural Networks](https://doi.org/10.1109/sp.2017.49)", .
