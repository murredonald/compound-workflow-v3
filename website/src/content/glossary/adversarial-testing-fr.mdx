---
term: "Tests adversariaux"
termSlug: "adversarial-testing"
short: "Soumettre le modèle à des entrées difficiles ou malveillantes pour révéler ses faiblesses."
category: "ai-ml"
category_name: "IA & Machine Learning"
related: ["stress-testing", "jailbreaking", "model-robustness"]
synonyms: ["Red teaming", "Évaluation adversariale"]
locale: "fr"
draft: false
---

## Définition

Les tests adversariaux exposent les systèmes d'IA à des cas extrêmes ou hostiles afin d'identifier des modes de défaillance.

## References

> Alexey Kurakin et al. (2016), "[Adversarial Machine Learning at Scale](https://arxiv.org/abs/1611.01236)", International Conference on Learning Representations.

> Florian Tramèr et al. (2017), "[Ensemble Adversarial Training: Attacks and Defenses](https://doi.org/10.48550/arxiv.1705.07204)", arXiv.

> Nicholas Carlini et al. (2017), "[Towards Evaluating the Robustness of Neural Networks](https://doi.org/10.1109/sp.2017.49)", .
