---
term: "Adversarial testing"
termSlug: "adversarial-testing"
short: "Gericht het model aanvallen met moeilijke of kwaadaardige inputs om zwaktes te vinden."
category: "ai-ml"
category_name: "AI & Machine Learning"
related: ["stress-testing", "jailbreaking", "model-robustness"]
synonyms: ["Red teaming", "Adversariële evaluatie"]
locale: "nl"
draft: false
---

## Definitie

Bij adversarial testing worden modellen blootgesteld aan lastige of vijandige [prompts](/nl/glossary/prompt/) om kwetsbaarheden vroegtijdig te ontdekken.

## References

> Alexey Kurakin et al. (2016), "[Adversarial Machine Learning at Scale](https://arxiv.org/abs/1611.01236)", International Conference on Learning Representations.

> Florian Tramèr et al. (2017), "[Ensemble Adversarial Training: Attacks and Defenses](https://doi.org/10.48550/arxiv.1705.07204)", arXiv.

> Nicholas Carlini et al. (2017), "[Towards Evaluating the Robustness of Neural Networks](https://doi.org/10.1109/sp.2017.49)", .
