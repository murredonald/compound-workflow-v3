---
term: "AI Risk Management"
termSlug: "ai-risk-management"
short: "AI risk management is the process of identifying, assessing, mitigating, and monitoring risks from AI systems across their lifecycle."
category: "business"
category_name: "Business"
related: ["responsible-ai", "ai-governance-framework", "eu-ai-act", "high-risk-ai-system", "human-oversight", "model-accountability", "data-ethics", "bias-mitigation"]
synonyms: ["AI RM", "Model risk management", "AI risk controls"]
locale: "en"
draft: false
---

## Definition

AI risk management is a disciplined approach to understanding and controlling how an AI system can fail, who it can harm, and what controls reduce that risk. It is continuous: risks change when data, models, users, or regulations change.

## Why it matters

- **High-stakes domains** (law, tax) need predictable and defensible behavior.
- **Regulation** increasingly expects documented risk controls.
- **Incidents** are expensive: reputational damage often exceeds technical cost.

## How it works

```
Identify -> assess -> mitigate -> monitor -> respond -> improve
```

Typical risks include: incorrect outputs, bias, data leakage, misuse, overreliance, and unclear accountability.

## Practical example

For an AI research tool, you track risks like hallucinated citations, stale law, and confidentiality. Controls include [source citation](/en/glossary/citation/), freshness checks, access control, and mandatory human review for client-facing advice.

## Common questions

**Q: Is AI risk management only for "high-risk" systems?**

A: No. The controls scale with impact. Even low-risk tools benefit from basic monitoring and documentation.

**Q: What is the most common failure mode in practice?**

A: Not the model itself — the process: unclear intended use, weak oversight, and no monitoring.

## Related terms

- [Responsible AI](/en/glossary/responsible-ai/) — the broader practice
- [AI Governance Framework](/en/glossary/ai-governance-framework/) — roles and controls
- [EU AI Act](/en/glossary/eu-ai-act/) — risk-based obligations
- [High-Risk AI System](/en/glossary/high-risk-ai-system/) — compliance triggers
- [Human Oversight](/en/glossary/human-oversight/) — intervention and review
- [Model Accountability](/en/glossary/model-accountability/) — ownership and traceability
- [Data Ethics](/en/glossary/data-ethics/) — safe data handling
- [Bias Mitigation](/en/glossary/bias-mitigation/) — reduce unfair outcomes

---

## References

> NIST (2023), *AI Risk Management Framework (AI RMF 1.0)*.

