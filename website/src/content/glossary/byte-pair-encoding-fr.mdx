---
term: "Byte Pair Encoding (BPE)"
termSlug: "byte-pair-encoding"
short: "Algorithme de tokenisation en sous-mots qui construit un vocabulaire en fusionnant itérativement les paires de symboles fréquentes."
category: "ai-ml"
category_name: "IA & Machine Learning"
related: []
synonyms: []
locale: "fr"
draft: false
---

## Définition

Byte Pair Encoding (BPE) est une méthode de [tokenisation](/fr/glossary/tokenization/) fondée sur les données qui part des caractères individuels et fusionne de façon répétée les paires de symboles adjacents les plus fréquentes pour créer un vocabulaire compact de sous-mots pour les modèles de langue.

## References

- Sennrich et al. (2016), "[Neural Machine Translation of Rare Words with Subword Units](https://doi.org/10.18653/v1/P16-1162)", ACL.

- Gage (1994), "[A New Algorithm for Data Compression](https://www.derczynski.com/papers/archive/BPE_Gage.pdf)", C Users Journal.

- Kudo & Richardson (2018), "[SentencePiece: A simple and language independent subword tokenizer and detokenizer](https://doi.org/10.18653/v1/D18-2012)", EMNLP.
