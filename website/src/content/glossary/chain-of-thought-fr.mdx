---
term: "Chain-of-Thought"
termSlug: "chain-of-thought"
short: "Une technique de prompting qui suscite un raisonnement étape par étape des modèles de langage, améliorant les performances sur les tâches complexes en rendant le processus de raisonnement explicite et vérifiable."
category: "ai-ml"
category_name: "IA & Machine Learning"
related: ["few-shot", "zero-shot", "in-context-learning", "prompt-engineering"]
synonyms: ["Prompting CoT", "Raisonnement étape par étape", "Chaîne de raisonnement"]
locale: "fr"
draft: false
---

## Définition

Le prompting chain-of-thought (CoT) est une technique qui encourage les grands modèles de langage à générer des étapes de raisonnement intermédiaires avant d'arriver à une réponse finale. Au lieu de produire directement une réponse, le modèle génère une série d'étapes logiques menant à la conclusion. Cette approche améliore significativement les performances sur les tâches nécessitant raisonnement multi-étapes, calcul mathématique, [inférence](/fr/glossary/inference/) logique et résolution de problèmes complexes. Le CoT peut être suscité par des exemples few-shot avec traces de raisonnement ou simplement en ajoutant "Réfléchissons étape par étape".

## Pourquoi c'est important

Chain-of-thought transforme les capacités des [LLM](/fr/glossary/llm/):

- **Boost de précision** — amélioration de 50-90% sur benchmarks de raisonnement
- **Transparence** — montre COMMENT le modèle est arrivé à sa réponse
- **Détection d'erreurs** — étapes intermédiaires révèlent logique fautive
- **Tâches complexes** — permet maths, logique, raisonnement multi-hop
- **Débogage** — identifier exactement où le raisonnement échoue
- **Construction de confiance** — raisonnement vérifiable pour décisions critiques

## Comment ça fonctionne

```
┌────────────────────────────────────────────────────────────┐
│                   CHAIN-OF-THOUGHT                          │
├────────────────────────────────────────────────────────────┤
│                                                            │
│  PROMPTING STANDARD vs CHAIN-OF-THOUGHT:                   │
│  ───────────────────────────────────────                   │
│                                                            │
│  Problème: "Jean a 3 pommes et achète 2 sacs              │
│           avec 4 pommes chacun. Combien en tout?"         │
│                                                            │
│                                                            │
│  PROMPTING STANDARD:                                       │
│  ┌─────────────────────────────────────────────────────┐ │
│  │  Utilisateur: [problème]                             │ │
│  │                                                      │ │
│  │  Modèle: 11 pommes  ← Réponse directe (souvent faux)│ │
│  │                                                      │ │
│  │  Pourquoi ça échoue:                                │ │
│  │  • Modèle peut manquer nature multi-étapes         │ │
│  │  • Pas de calcul intermédiaire                     │ │
│  │  • Impossible vérifier raisonnement                │ │
│  └─────────────────────────────────────────────────────┘ │
│                                                            │
│                                                            │
│  PROMPTING CHAIN-OF-THOUGHT:                               │
│  ┌─────────────────────────────────────────────────────┐ │
│  │  Utilisateur: [problème]                             │ │
│  │        Réfléchissons étape par étape.               │ │
│  │                                                      │ │
│  │  Modèle:                                             │ │
│  │  Étape 1: Jean commence avec 3 pommes               │ │
│  │  Étape 2: Il achète 2 sacs                          │ │
│  │  Étape 3: Chaque sac contient 4 pommes              │ │
│  │  Étape 4: Pommes des sacs = 2 × 4 = 8              │ │
│  │  Étape 5: Total = 3 + 8 = 11 pommes                │ │
│  │                                                      │ │
│  │  Réponse: 11 pommes ✓                               │ │
│  │                                                      │ │
│  └─────────────────────────────────────────────────────┘ │
│                                                            │
│                                                            │
│  VARIANTES COT:                                            │
│  ──────────────                                            │
│                                                            │
│  1. COT ZERO-SHOT:                                         │
│  ┌─────────────────────────────────────────────────────┐ │
│  │  Ajouter "Réfléchissons étape par étape"           │ │
│  │                                                      │ │
│  │  Prompt: "Que fait 17 × 24?"                        │ │
│  │          "Réfléchissons étape par étape."          │ │
│  │                                                      │ │
│  │  Modèle: "D'abord, je décompose:                    │ │
│  │          17 × 24 = 17 × (20 + 4)                   │ │
│  │                  = 17 × 20 + 17 × 4                │ │
│  │                  = 340 + 68                         │ │
│  │                  = 408"                             │ │
│  └─────────────────────────────────────────────────────┘ │
│                                                            │
│  2. COT FEW-SHOT (avec exemples):                         │
│  ┌─────────────────────────────────────────────────────┐ │
│  │  Exemple 1:                                          │ │
│  │  Q: Un magasin a 5 boîtes. Chaque boîte 3 items.   │ │
│  │     2 items sont vendus. Combien restent?          │ │
│  │  R: Réfléchissons étape par étape.                 │ │
│  │     Étape 1: Total items = 5 × 3 = 15             │ │
│  │     Étape 2: Après vente: 15 - 2 = 13             │ │
│  │     Réponse: 13 items                              │ │
│  │                                                      │ │
│  │  Maintenant résoudre:                               │ │
│  │  Q: [nouveau problème]                              │ │
│  │                                                      │ │
│  │  Modèle suit le patron de raisonnement démontré!   │ │
│  └─────────────────────────────────────────────────────┘ │
│                                                            │
│                                                            │
│  TECHNIQUES COT AVANCÉES:                                  │
│  ────────────────────────                                  │ │
│                                                            │
│  SELF-CONSISTENCY:                                         │
│  ┌─────────────────────────────────────────────────────┐ │
│  │  Générer multiples chemins, voter sur réponse      │ │
│  │                                                      │ │
│  │  Chemin 1: 3 + (2×4) = 3 + 8 = 11 ←─┐              │ │
│  │  Chemin 2: 3 + 4 + 4 = 11           ←─┼─ Vote: 11 ✓│ │
│  │  Chemin 3: 3×2 + 4 = 10 (faux)     ←─┘              │ │
│  │                                                      │ │
│  │  Vote majoritaire filtre erreurs de raisonnement   │ │
│  └─────────────────────────────────────────────────────┘ │
│                                                            │
│                                                            │
│  AMÉLIORATIONS BENCHMARKS AVEC COT:                        │
│  ──────────────────────────────────                        │
│                                                            │
│  ┌────────────────────┬─────────────┬───────────────────┐│
│  │ Benchmark          │ Standard    │ Avec CoT          ││
│  ├────────────────────┼─────────────┼───────────────────┤│
│  │ GSM8K (maths)      │ ~18%        │ ~57% (+217%)      ││
│  │ MultiArith         │ ~35%        │ ~93% (+166%)      ││
│  │ StrategyQA         │ ~65%        │ ~75% (+15%)       ││
│  └────────────────────┴─────────────┴───────────────────┘│
│                                                            │
│  (Résultats varient selon taille modèle)                  │
│                                                            │
└────────────────────────────────────────────────────────────┘
```

## Questions fréquentes

**Q: Quand utiliser le prompting chain-of-thought?**

R: Utiliser CoT pour: (1) problèmes mathématiques, (2) raisonnement multi-étapes, (3) inférence logique, (4) tâches nécessitant explication, (5) prise de décision complexe. Éviter CoT pour questions factuelles simples ou tâches créatives.

**Q: CoT fonctionne-t-il avec modèles plus petits?**

R: Bénéfices CoT augmentent dramatiquement avec taille modèle. Modèles sous ~10B paramètres montrent amélioration minimale. CoT "émerge" comme capacité dans grands modèles (62B+).

**Q: Comment gérer erreurs CoT quand raisonnement est faux mais confiant?**

R: Utiliser self-consistency (générer 5-10 chemins, voter), ajouter étapes vérification, ou implémenter vérification explicite avec second modèle.

**Q: CoT est-il juste prompting ou modèles peuvent être entraînés?**

R: Les deux. Prompting extrait capacité latente. Entraînement sur traces de raisonnement améliore significativement qualité CoT.

## Termes associés

- [Few-shot learning](/fr/glossary/few-shot/) — fournir exemples pour CoT
- [Zero-shot learning](/fr/glossary/zero-shot/) — CoT sans exemples
- [In-context learning](/fr/glossary/in-context-learning/) — patron d'apprentissage utilisé
- Prompt engineering — techniques prompting plus larges

---

## Références

> Wei et al. (2022), "[Chain-of-Thought Prompting Elicits Reasoning in Large Language Models](https://arxiv.org/abs/2201.11903)", NeurIPS. [Article CoT original]

> Kojima et al. (2022), "[Large Language Models are Zero-Shot Reasoners](https://arxiv.org/abs/2205.11916)", NeurIPS. [Zero-shot CoT]

> Wang et al. (2022), "[Self-Consistency Improves Chain of Thought Reasoning](https://arxiv.org/abs/2203.11171)", ICLR. [Self-consistency pour CoT]

> Yao et al. (2023), "[Tree of Thoughts: Deliberate Problem Solving with Large Language Models](https://arxiv.org/abs/2305.10601)", NeurIPS. [Extension Tree of Thoughts]

## References

> Wei et al. (2022), "[Chain-of-Thought Prompting Elicits Reasoning in Large Language Models](https://arxiv.org/abs/2201.11903)", NeurIPS. [Original CoT paper]

> Kojima et al. (2022), "[Large Language Models are Zero-Shot Reasoners](https://arxiv.org/abs/2205.11916)", NeurIPS. [Zero-shot CoT "Let's think step by step"]

> Wang et al. (2022), "[Self-Consistency Improves Chain of Thought Reasoning](https://arxiv.org/abs/2203.11171)", ICLR. [Self-consistency for CoT]

> Yao et al. (2023), "[Tree of Thoughts: Deliberate Problem Solving with Large Language Models](https://arxiv.org/abs/2305.10601)", NeurIPS. [Tree of Thoughts extension]
