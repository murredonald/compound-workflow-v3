---
term: "Kontextinjektion"
termSlug: "context-injection"
short: "Das Hinzuf체gen abgerufener oder zus채tzlicher Informationen in einen LLM-Prompt, um die Generierung zu steuern."
category: "ai-ml"
category_name: "KI & Machine Learning"
related: ["rag", "prompt", "grounding"]
synonyms: ["Prompt-Kontextinjektion", "Context stuffing"]
locale: "de"
draft: false
---

## Definition

Kontextinjektion bedeutet, relevante Dokumente, Snippets oder Metadaten in einen [LLM](/de/glossary/llm/)-[Prompt](/de/glossary/prompt/) einzuf체gen, damit das Modell seine Antwort auf diese externen Informationen st체tzt.

## References

> Wenxiao Zhang et al. (2024), "[A Study on Prompt Injection Attack Against LLM-Integrated Mobile Robotic Systems](https://arxiv.org/abs/2408.03515)", 2024 IEEE 35th International Symposium on Software Reliability Engineering Workshops (ISSREW).

> Rafael Ferreira Mello et al. (2025), "[Automatic Short Answer Grading in the LLM Era: Does GPT-4 with Prompt Engineering beat Traditional Models?](https://doi.org/10.1145/3706468.3706481)", International Conference on Learning Analytics and Knowledge.

> Xin Yin et al. (2025), "[Enhancing LLM's Ability to Generate More Repository-Aware Unit Tests Through Precise Contextual Information Injection](https://arxiv.org/abs/2501.07425)", arXiv.
