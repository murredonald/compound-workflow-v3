---
term: "Context injection"
termSlug: "context-injection"
short: "The practice of adding retrieved or auxiliary information into an LLM prompt to guide generation."
category: "ai-ml"
category_name: "AI & Machine Learning"
related: ["rag", "prompt", "grounding"]
synonyms: ["Prompt injection of context", "Context stuffing"]
locale: "en"
draft: false
---

## Definition

Context injection means taking relevant documents, snippets, or metadata and inserting them into an [LLM](/en/glossary/llm/) [prompt](/en/glossary/prompt/) so that the model can condition its answer on that external information.

## References

> Wenxiao Zhang et al. (2024), "[A Study on Prompt Injection Attack Against LLM-Integrated Mobile Robotic Systems](https://arxiv.org/abs/2408.03515)", 2024 IEEE 35th International Symposium on Software Reliability Engineering Workshops (ISSREW).

> Rafael Ferreira Mello et al. (2025), "[Automatic Short Answer Grading in the LLM Era: Does GPT-4 with Prompt Engineering beat Traditional Models?](https://doi.org/10.1145/3706468.3706481)", International Conference on Learning Analytics and Knowledge.

> Xin Yin et al. (2025), "[Enhancing LLM's Ability to Generate More Repository-Aware Unit Tests Through Precise Contextual Information Injection](https://arxiv.org/abs/2501.07425)", arXiv.
