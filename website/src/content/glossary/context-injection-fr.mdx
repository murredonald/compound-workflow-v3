---
term: "Injection de contexte"
termSlug: "context-injection"
short: "Le fait d’ajouter des informations récupérées ou auxiliaires dans un prompt LLM pour guider la génération."
category: "ai-ml"
category_name: "IA & Machine Learning"
related: ["rag", "prompt", "grounding"]
synonyms: ["Injection de contexte dans le prompt", "Context stuffing"]
locale: "fr"
draft: false
---

## Definition

L’injection de contexte consiste à insérer dans un [prompt](/fr/glossary/prompt/) LLM des documents, extraits ou métadonnées pertinents afin que le modèle conditionne sa réponse sur ces informations externes.

## References

> Wenxiao Zhang et al. (2024), "[A Study on Prompt Injection Attack Against LLM-Integrated Mobile Robotic Systems](https://arxiv.org/abs/2408.03515)", 2024 IEEE 35th International Symposium on Software Reliability Engineering Workshops (ISSREW).

> Rafael Ferreira Mello et al. (2025), "[Automatic Short Answer Grading in the LLM Era: Does GPT-4 with Prompt Engineering beat Traditional Models?](https://doi.org/10.1145/3706468.3706481)", International Conference on Learning Analytics and Knowledge.

> Xin Yin et al. (2025), "[Enhancing LLM's Ability to Generate More Repository-Aware Unit Tests Through Precise Contextual Information Injection](https://arxiv.org/abs/2501.07425)", arXiv.
