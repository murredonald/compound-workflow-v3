---
term: "Deep Learning"
termSlug: "deep-learning"
short: "Een deelveld van machine learning dat neurale netwerken met veel lagen gebruikt om hiÃ«rarchische representaties van data te leren."
category: "ai-ml"
category_name: "AI & Machine Learning"
related: ["neural-network", "transformer-architecture", "backpropagation", "llm"]
synonyms: ["Diepe neurale netwerken", "DNN", "HiÃ«rarchisch leren", "Representatie leren"]
locale: "nl"
draft: false
---

## Definitie

Deep learning is een tak van machine learning die kunstmatige neurale netwerken met meerdere lagen (vandaar "diep") gebruikt om automatisch hiÃ«rarchische representaties van data te leren. In tegenstelling tot ondiepe modellen die handgemaakte features vereisen, leren deep learning systemen steeds abstractere features op elke laagâ€”van randen en texturen in afbeeldingen tot semantische concepten, of van karakters naar woorden naar zinnen naar betekenis in tekst.

## Waarom het belangrijk is

Deep learning revolutioneerde AI:

- **Automatische feature extractie** â€” geen handmatige feature engineering nodig
- **HiÃ«rarchische abstractie** â€” leert concepten op meerdere niveaus
- **Schaalbare prestaties** â€” verbetert met meer data en rekenkracht
- **Transfer learning** â€” voorgetrainde modellen passen zich aan nieuwe taken aan
- **Doorbraakresultaten** â€” drijft beeldherkenning, NLP, AlphaGo, LLMs

Elke grote AI-vooruitgang sinds 2012 is door deep learning aangedreven.

## Hoe het werkt

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      DEEP LEARNING                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                            â”‚
â”‚  ONDIEP VS DIEP ARCHITECTUUR:                              â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                              â”‚
â”‚                                                            â”‚
â”‚  ONDIEP (1-2 lagen):            DIEP (veel lagen):        â”‚
â”‚                                                            â”‚
â”‚  Input â”€â”€â–º Hidden â”€â”€â–º Output    Input                     â”‚
â”‚                                   â”‚                        â”‚
â”‚                                   â–¼                        â”‚
â”‚                                 Laag 1 (laag-niveau)       â”‚
â”‚                                   â”‚                        â”‚
â”‚                                   â–¼                        â”‚
â”‚                                 Laag 2                     â”‚
â”‚                                   â”‚                        â”‚
â”‚                                   â–¼                        â”‚
â”‚                                 Laag 3                     â”‚
â”‚                                   â”‚                        â”‚
â”‚                                   â–¼                        â”‚
â”‚                                 ...                        â”‚
â”‚                                   â”‚                        â”‚
â”‚                                   â–¼                        â”‚
â”‚                                 Laag N (hoog-niveau)       â”‚
â”‚                                   â”‚                        â”‚
â”‚                                   â–¼                        â”‚
â”‚                                 Output                     â”‚
â”‚                                                            â”‚
â”‚  HIÃ‹RARCHISCH FEATURE LEREN (Afbeelding Voorbeeld):        â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€        â”‚
â”‚                                                            â”‚
â”‚  Laag 1:   â”Œâ”€â”€â”€â” â”Œâ”€â”€â”€â” â”Œâ”€â”€â”€â”                              â”‚
â”‚  (Randen)  â”‚ / â”‚ â”‚ â”€ â”‚ â”‚ \ â”‚   Detecteert randen         â”‚
â”‚            â””â”€â”€â”€â”˜ â””â”€â”€â”€â”˜ â””â”€â”€â”€â”˜                              â”‚
â”‚                   â”‚                                        â”‚
â”‚                   â–¼                                        â”‚
â”‚  Laag 2:   â”Œâ”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”                                â”‚
â”‚  (Vormen)  â”‚  â—‹  â”‚ â”‚ â–¡â”€â”€ â”‚   Combineert tot vormen       â”‚
â”‚            â””â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”˜                                â”‚
â”‚                   â”‚                                        â”‚
â”‚                   â–¼                                        â”‚
â”‚  Laag 3:   â”Œâ”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”                            â”‚
â”‚  (Delen)   â”‚ (â—•â€¿â—•) â”‚ â”‚  ðŸ¦»   â”‚   Vormt objectdelen        â”‚
â”‚            â””â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”˜                            â”‚
â”‚                   â”‚                                        â”‚
â”‚                   â–¼                                        â”‚
â”‚  Laag N:   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                            â”‚
â”‚  (Object)  â”‚     "KAT"       â”‚   Herkent volledige obj.   â”‚
â”‚            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                            â”‚
â”‚                                                            â”‚
â”‚  DEEP LEARNING ARCHITECTUREN:                              â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                              â”‚
â”‚  CNNs:        Afbeeldingen, ruimtelijke patronen          â”‚
â”‚  RNNs/LSTMs:  Sequenties, tijdreeksen                     â”‚
â”‚  Transformers: Taal, visie (dominant vandaag)             â”‚
â”‚  GANs:        Generatieve taken                           â”‚
â”‚  Autoencoders: Compressie, denoising                      â”‚
â”‚                                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Waarom diepte belangrijk is:**
| Aspect | Ondiep Netwerk | Diep Netwerk |
|--------|----------------|--------------|
| Feature leren | Handmatig of beperkt | Automatisch, hiÃ«rarchisch |
| Abstractie | Enkel niveau | Meerdere niveaus |
| Expressiviteit | Beperkte complexiteit | Zeer complexe functies |
| Data-efficiÃ«ntie | Meer data per feature nodig | Leert herbruikbare features |

## Veelgestelde vragen

**V: Hoeveel lagen maken een netwerk "diep"?**

A: Over het algemeen wordt 3+ hidden layers als "diep" beschouwd, hoewel moderne LLMs 32-100+ lagen hebben. De term is relatiefâ€”wat "diep" was in 2010 (5-8 lagen) is vandaag ondiep. Diepte gaat over het leren van hiÃ«rarchische representaties, niet een vast aantal.

**V: Waarom kwam deep learning op in 2012?**

A: Drie factoren kwamen samen: (1) GPUs maakten training van grote netwerken mogelijk, (2) grote datasets zoals ImageNet werden beschikbaar, (3) algoritmische verbeteringen zoals ReLU activering en dropout verbeterden training. AlexNet's ImageNet overwinning demonstreerde het potentieel.

**V: Wat is de relatie tussen deep learning en AI?**

A: Deep learning is een subset van machine learning, wat een subset is van AI. Niet alle AI gebruikt deep learning (regelgebaseerde systemen niet), en niet alle machine learning is diep (beslisbomen, SVMs niet). Maar deep learning drijft nu de meeste geavanceerde AI-systemen.

**V: Kan deep learning elk probleem oplossen?**

A: Nee. Deep learning excelleert in [patroonherkenning](/nl/glossary/machine-learning/) met veel data maar heeft moeite met: kleine datasets, redeneren, causale [inferentie](/nl/glossary/inference/), extrapolatie buiten trainingsdata, en taken die expliciete symbolische logica vereisen. Het is een krachtig gereedschap, geen universele oplossing.

## Gerelateerde termen

- [Neuraal Netwerk](/nl/glossary/neural-network/) â€” het fundament van deep learning
- [Transformer Architectuur](/nl/glossary/transformer-architecture/) â€” dominante diepe architectuur
- [Backpropagation](/nl/glossary/backpropagation/) â€” algoritme dat deep learning mogelijk maakt
- [LLM](/nl/glossary/llm/) â€” grootschalig deep learning voor taal

---

## Referenties

> LeCun et al. (2015), "[Deep Learning](https://www.nature.com/articles/nature14539)", Nature. [40.000+ [citaties](/nl/glossary/citation/)]

> Goodfellow et al. (2016), "[Deep Learning](https://www.deeplearningbook.org/)", MIT Press. [Uitgebreid leerboek]

> Krizhevsky et al. (2012), "[ImageNet Classification with Deep CNNs](https://papers.nips.cc/paper/2012/hash/c399862d3b9d6b76c8436e924a68c45b-Abstract.html)", NeurIPS. [AlexNet - startte deep learning revolutie]

> Bengio et al. (2013), "[Representation Learning: A Review](https://arxiv.org/abs/1206.5538)", IEEE TPAMI. [15.000+ citaties]

## References

> LeCun et al. (2015), "[Deep Learning](https://www.nature.com/articles/nature14539)", Nature. [40,000+ citations]

> Goodfellow et al. (2016), "[Deep Learning](https://www.deeplearningbook.org/)", MIT Press. [Comprehensive textbook]

> Krizhevsky et al. (2012), "[ImageNet Classification with Deep CNNs](https://papers.nips.cc/paper/2012/hash/c399862d3b9d6b76c8436e924a68c45b-Abstract.html)", NeurIPS. [AlexNet - sparked deep learning revolution]

> Bengio et al. (2013), "[Representation Learning: A Review](https://arxiv.org/abs/1206.5538)", IEEE TPAMI. [15,000+ citations]
