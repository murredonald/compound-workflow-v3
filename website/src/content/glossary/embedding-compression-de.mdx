---
term: "Embedding Compression"
termSlug: "embedding-compression"
short: "Verfahren, die Embeddings in Speicher oder Bits pro Vektor verkleinern, ohne die Qualität stark zu mindern."
category: "ai-ml"
category_name: "KI & Machine Learning"
related: ["vector-quantization", "dimensionality-reduction", "index-sharding"]
synonyms: ["Vektorkompression", "Embedding-Kompression"]
locale: "de"
draft: false
---

## Definition

Embedding Compression setzt etwa geringere Präzision, Product‑[Quantization](/de/glossary/quantization/) oder Hashing ein, um den Speicher pro Embedding zu verringern und damit größere Korpora kostengünstig zu indexieren.

## References

> Song Han et al. (2015), "[Deep Compression: Compressing Deep Neural Networks with Pruning, Trained Quantization and Huffman Coding](https://doi.org/10.48550/arxiv.1510.00149)", arXiv.

> Lei Deng et al. (2020), "[Model Compression and Hardware Acceleration for Neural Networks: A Comprehensive Survey](https://doi.org/10.1109/jproc.2020.2976475)", Proceedings of the IEEE.

> Francesco Marcelloni et al. (2010), "[Enabling energy-efficient and lossy-aware data compression in wireless sensor networks by multi-objective evolutionary optimization](https://doi.org/10.1016/j.ins.2010.01.027)", Information Sciences.
