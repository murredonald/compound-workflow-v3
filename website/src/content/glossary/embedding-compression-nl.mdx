---
term: "Embedding compression"
termSlug: "embedding-compression"
short: "Technieken om embeddings kleiner te maken in opslag of bits per vector zonder te veel kwaliteitsverlies."
category: "ai-ml"
category_name: "AI & Machine Learning"
related: ["vector-quantization", "dimensionality-reduction", "index-sharding"]
synonyms: ["Vectorcompressie", "Embedding‑compressie"]
locale: "nl"
draft: false
---

## Definition

Embedding compression gebruikt bijvoorbeeld lagere precisie, product‑[quantization](/nl/glossary/quantization/) of hashing om de opslag per embedding te verlagen en zo grotere corpora betaalbaar te indexeren.

## References

> Song Han et al. (2015), "[Deep Compression: Compressing Deep Neural Networks with Pruning, Trained Quantization and Huffman Coding](https://doi.org/10.48550/arxiv.1510.00149)", arXiv.

> Lei Deng et al. (2020), "[Model Compression and Hardware Acceleration for Neural Networks: A Comprehensive Survey](https://doi.org/10.1109/jproc.2020.2976475)", Proceedings of the IEEE.

> Francesco Marcelloni et al. (2010), "[Enabling energy-efficient and lossy-aware data compression in wireless sensor networks by multi-objective evolutionary optimization](https://doi.org/10.1016/j.ins.2010.01.027)", Information Sciences.
