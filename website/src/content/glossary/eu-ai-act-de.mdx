---
term: "EU AI Act"
termSlug: "eu-ai-act"
short: "Der EU AI Act ist die risikobasierte EU-Verordnung für KI und legt Pflichten für Anbieter und Deployer je nach Systemrisiko fest."
category: "ai-regulation"
category_name: "KI-Regulierung"
related: ["high-risk-ai-system", "ai-conformity-assessment", "ai-documentation-requirements", "human-oversight", "algorithmic-transparency", "ai-risk-management"]
synonyms: ["AI Act", "Verordnung (EU) 2024/1689"]
locale: "de"
draft: false
---

## Definition

Der EU AI Act ist eine EU-Verordnung, die KI-Systeme risikobasiert reguliert. Er definiert verbotene Praktiken, strengere Pflichten für bestimmte Anwendungen (insbesondere Hochrisiko-Systeme) und Transparenzanforderungen für bestimmte Interaktionen.

## Warum es wichtig ist

- **Compliance**: konkrete Anforderungen an Design und Betrieb von KI.
- **Verträge und Procurement**: Nachweise (Dokumentation, Kontrollen) werden verlangt.
- **Operativer Impact**: Governance, Aufsicht und Monitoring werden für bestimmte Systeme verpflichtend.

## Wie es funktioniert

```
Rolle bestimmen + Risiko klassifizieren -> Anforderungen umsetzen -> dokumentieren -> überwachen
```

Typische Schritte: Zweck definieren, prüfen ob regulierte Kategorie, Risikokontrollen implementieren und erforderliche Dokumentation/Logs pflegen.

## Praktisches Beispiel

Ein KI-Tool in einem regulierten Workflow wird auf Hochrisiko-Einstufung geprüft. Bei Hochrisiko: Provider-Dokumentation und Konformitätsprozess; Deployer stellt menschliche Aufsicht und korrekte Nutzung sicher.

## Häufige Fragen

**Q: Gilt der EU AI Act für jedes KI-Tool?**

A: Nein. Pflichten hängen von Systemtyp, Zweck, Rolle und Risikoklassifizierung ab.

**Q: Ist das nur ein Provider-Thema?**

A: Nicht immer. Deployer können ebenfalls Pflichten haben, insbesondere bei Hochrisiko-Systemen.

## Verwandte Begriffe

- [Hochrisiko-KI-System](/de/glossary/high-risk-ai-system/) — wann strenge Pflichten gelten
- [AI-Konformitätsbewertung](/de/glossary/ai-conformity-assessment/) — erforderlicher Prozess
- [AI-Dokumentationsanforderungen](/de/glossary/ai-documentation-requirements/) — Nachweise
- [Menschliche Aufsicht](/de/glossary/human-oversight/) — sinnvolle Kontrolle
- [Algorithmische Transparenz](/de/glossary/algorithmic-transparency/) — Disclosure und Limits
- [AI Risk Management](/de/glossary/ai-risk-management/) — Risikokontrollen

---

## Referenzen

> Verordnung (EU) 2024/1689 (EU AI Act).

## References

> Regulation (EU) 2024/1689 (EU AI Act).
