---
term: "EU AI Act"
termSlug: "eu-ai-act"
short: "LÃ¢â‚¬â„¢EU AI Act est le rÃƒÂ¨glement europÃƒÂ©en basÃƒÂ© sur le risque pour lÃ¢â‚¬â„¢IA, imposant des obligations aux fournisseurs et dÃƒÂ©ployeurs selon le niveau de risque."
category: "ai-regulation"
category_name: "Réglementation IA"
related: ["high-risk-ai-system", "ai-conformity-assessment", "ai-documentation-requirements", "human-oversight", "algorithmic-transparency", "ai-risk-management"]
synonyms: ["AI Act", "RÃƒÂ¨glement (UE) 2024/1689"]
locale: "fr"
draft: false
---

## DÃƒÂ©finition

LÃ¢â‚¬â„¢EU AI Act est un rÃƒÂ¨glement de lÃ¢â‚¬â„¢UE qui encadre les systÃƒÂ¨mes dÃ¢â‚¬â„¢IA via une approche fondÃƒÂ©e sur le risque. Il dÃƒÂ©finit des pratiques interdites, impose des obligations renforcÃƒÂ©es pour certains usages (notamment les systÃƒÂ¨mes ÃƒÂ  haut risque) et prÃƒÂ©voit des exigences de transparence pour certaines interactions.

## Pourquoi c'est important

- **ConformitÃƒÂ©**: exigences concrÃƒÂ¨tes sur conception et usage de lÃ¢â‚¬â„¢IA.
- **Contrats et achats**: demande de preuves (docs, contrÃƒÂ´les).
- **Impact opÃƒÂ©rationnel**: gouvernance, supervision et monitoring peuvent devenir obligatoires.

## Comment ÃƒÂ§a fonctionne

```
DÃƒÂ©finir le rÃƒÂ´le + classifier le risque -> appliquer exigences -> documenter -> surveiller
```

Ãƒâ€°tapes typiques: dÃƒÂ©finir lÃ¢â‚¬â„¢usage prÃƒÂ©vu, vÃƒÂ©rifier la catÃƒÂ©gorie rÃƒÂ©glementÃƒÂ©e, mettre en place des contrÃƒÂ´les de risque et maintenir documentation et logs.

## Exemple pratique

Un outil IA dans un flux rÃƒÂ©glementÃƒÂ© est ÃƒÂ©valuÃƒÂ© pour dÃƒÂ©terminer sÃ¢â‚¬â„¢il est ÃƒÂ  haut risque. Si oui, le fournisseur prÃƒÂ©pare la documentation et la conformitÃƒÂ©; le dÃƒÂ©ployeur assure supervision humaine et usage correct.

## Questions frÃƒÂ©quentes

**Q: Le rÃƒÂ¨glement sÃ¢â‚¬â„¢applique-t-il ÃƒÂ  tous les outils IA?**

R: Non. Les obligations dÃƒÂ©pendent du type de systÃƒÂ¨me, de lÃ¢â‚¬â„¢usage prÃƒÂ©vu, du rÃƒÂ´le et de la classification de risque.

**Q: Est-ce uniquement un sujet "fournisseur"?**

R: Pas toujours. Les dÃƒÂ©ployeurs peuvent aussi avoir des obligations, surtout pour les systÃƒÂ¨mes ÃƒÂ  haut risque.

## Termes associÃƒÂ©s

- [SystÃƒÂ¨me d'IA ÃƒÂ  haut risque](/fr/glossary/high-risk-ai-system/) Ã¢â‚¬â€ obligations renforcÃƒÂ©es
- [Ãƒâ€°valuation de conformitÃƒÂ© IA](/fr/glossary/ai-conformity-assessment/) Ã¢â‚¬â€ procÃƒÂ©dure exigÃƒÂ©e
- [Exigences de documentation IA](/fr/glossary/ai-documentation-requirements/) Ã¢â‚¬â€ preuves et informations
- [Supervision humaine](/fr/glossary/human-oversight/) Ã¢â‚¬â€ contrÃƒÂ´le humain
- [Transparence algorithmique](/fr/glossary/algorithmic-transparency/) Ã¢â‚¬â€ disclosures et limites
- [Gestion des risques IA](/fr/glossary/ai-risk-management/) Ã¢â‚¬â€ contrÃƒÂ´les en pratique

---

## RÃƒÂ©fÃƒÂ©rences

> RÃƒÂ¨glement (UE) 2024/1689 (EU AI Act).

## References

> Regulation (EU) 2024/1689 (EU AI Act).
