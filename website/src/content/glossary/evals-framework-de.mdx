---
term: "Evals-Framework"
termSlug: "evals-framework"
short: "Wiederverwendbare Umgebung zum Definieren, Ausführen und Nachverfolgen von KI-Evaluationen."
category: "ai-ml"
category_name: "KI & Machine Learning"
related: ["evaluation-dataset", "benchmarking", "continuous-evaluation"]
synonyms: ["Evaluierungs-Framework"]
locale: "de"
draft: false
---

## Definition

Ein Evals-Framework stellt Werkzeuge und Konfiguration bereit, um feste Eval-Suites reproduzierbar auszuführen und zu versionieren.

## References

> K. Singhal et al. (2022), "[Large language models encode clinical knowledge](https://arxiv.org/abs/2212.13138)", Nature.

> Jiawei Liu et al. (2023), "[Is Your Code Generated by ChatGPT Really Correct? Rigorous Evaluation of Large Language Models for Code Generation](https://arxiv.org/abs/2305.01210)", Neural Information Processing Systems.

> Yunfan Gao et al. (2023), "[Retrieval-Augmented Generation for Large Language Models: A Survey](https://doi.org/10.48550/arxiv.2312.10997)", arXiv.
