---
term: "Evals-framework"
termSlug: "evals-framework"
short: "Herbruikbare opzet om evaluaties van AI-systemen te definiÃ«ren, draaien en opvolgen."
category: "ai-ml"
category_name: "AI & Machine Learning"
related: ["evaluation-dataset", "benchmarking", "continuous-evaluation"]
synonyms: ["Evaluatiekader", "Evals-harnas"]
locale: "nl"
draft: false
---

## Definitie

Een evals-framework biedt tooling en configuratie om vaste evaluatiescenario's herhaalbaar uit te voeren en te loggen.

## References

> K. Singhal et al. (2022), "[Large language models encode clinical knowledge](https://arxiv.org/abs/2212.13138)", Nature.

> Jiawei Liu et al. (2023), "[Is Your Code Generated by ChatGPT Really Correct? Rigorous Evaluation of Large Language Models for Code Generation](https://arxiv.org/abs/2305.01210)", Neural Information Processing Systems.

> Yunfan Gao et al. (2023), "[Retrieval-Augmented Generation for Large Language Models: A Survey](https://doi.org/10.48550/arxiv.2312.10997)", arXiv.
