---
term: "ExplicabilitÃ©"
termSlug: "explainability"
short: "La capacitÃ© de comprendre, interprÃ©ter et expliquer comment les modÃ¨les IA/ML font des prÃ©dictionsâ€”essentiel pour la confiance, le dÃ©bogage, la conformitÃ© rÃ©glementaire et le dÃ©ploiement responsable de l'IA."
category: "ai-ml"
category_name: "IA & Machine Learning"
related: ["interpretability", "transparency", "black-box", "xai", "feature-importance", "ai-act"]
synonyms: ["InterprÃ©tabilitÃ©", "XAI", "IA explicable", "Transparence des modÃ¨les"]
locale: "fr"
draft: false
---

## DÃ©finition

L'explicabilitÃ© (ou IA Explicable/XAI) fait [rÃ©fÃ©rence](/fr/glossary/citation/) aux techniques qui rendent les dÃ©cisions des modÃ¨les IA comprÃ©hensibles pour les humains. Elle rÃ©pond Ã  "pourquoi le modÃ¨le a-t-il fait cette [prÃ©diction](/fr/glossary/inference/)?" plutÃ´t que simplement "qu'est-ce que le modÃ¨le a prÃ©dit?" L'explicabilitÃ© existe sur un spectre: des modÃ¨les intrinsÃ¨quement interprÃ©tables (rÃ©gression linÃ©aire, arbres de dÃ©cision) aux explications post-hoc pour les modÃ¨les boÃ®te noire (SHAP, LIME, visualisation d'attention). Ã€ mesure que les systÃ¨mes IA prennent des dÃ©cisions de plus en plus importantes (santÃ©, finance, juridique), l'explicabilitÃ© devient cruciale pour la confiance, la responsabilitÃ©, le dÃ©bogage et la conformitÃ© rÃ©glementaire ([AI Act](/fr/glossary/eu-ai-act/), RGPD Article 22).

## Pourquoi c'est important

L'explicabilitÃ© rÃ©pond aux besoins critiques de dÃ©ploiement IA:

- **Confiance** â€” les utilisateurs font confiance aux systÃ¨mes qu'ils comprennent
- **DÃ©bogage** â€” identifier pourquoi les modÃ¨les Ã©chouent sur des cas spÃ©cifiques
- **ConformitÃ© rÃ©glementaire** â€” AI Act exige explications pour IA haut-risque
- **DÃ©tection biais** â€” rÃ©vÃ©ler si modÃ¨les utilisent attributs protÃ©gÃ©s
- **Validation domaine** â€” experts vÃ©rifient que raisonnement modÃ¨le est valide
- **DÃ©fendabilitÃ© juridique** â€” expliquer dÃ©cisions automatisÃ©es contestÃ©es

## Comment Ã§a fonctionne

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     EXPLICABILITÃ‰                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                            â”‚
â”‚  LE SPECTRE DE L'EXPLICABILITÃ‰:                            â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                            â”‚
â”‚                                                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚                                                      â”‚ â”‚
â”‚  â”‚    INTERPRÃ‰TABLE           â†’           BOÃTE NOIRE  â”‚ â”‚
â”‚  â”‚    (intÃ©grÃ©)                         (nÃ©cessite XAI)â”‚ â”‚
â”‚  â”‚                                                      â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”‚
â”‚  â”‚  â”‚  RÃ‰GRESSION â”‚  â”‚   FORÃŠT     â”‚  â”‚  RÃ‰SEAU     â”‚ â”‚ â”‚
â”‚  â”‚  â”‚   LINÃ‰AIRE  â”‚  â”‚  ALÃ‰ATOIRE  â”‚  â”‚  NEURONAL   â”‚ â”‚ â”‚
â”‚  â”‚  â”‚             â”‚  â”‚             â”‚  â”‚  PROFOND    â”‚ â”‚ â”‚
â”‚  â”‚  â”‚ coefficient â”‚  â”‚ importance  â”‚  â”‚             â”‚ â”‚ â”‚
â”‚  â”‚  â”‚ = explicationâ”‚ â”‚ features    â”‚  â”‚ ğŸ¤· ???     â”‚ â”‚ â”‚
â”‚  â”‚  â”‚ directe     â”‚  â”‚ disponible  â”‚  â”‚ Besoin SHAP â”‚ â”‚ â”‚
â”‚  â”‚  â”‚             â”‚  â”‚             â”‚  â”‚ LIME, etc.  â”‚ â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚
â”‚  â”‚                                                      â”‚ â”‚
â”‚  â”‚  â—„â”€â”€â”€ Plus interprÃ©table    Moins interprÃ©table â”€â”€â–º â”‚ â”‚
â”‚  â”‚  â—„â”€â”€â”€ Moins puissant        Plus puissant â”€â”€â–º       â”‚ â”‚
â”‚  â”‚                                                      â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                            â”‚
â”‚                                                            â”‚
â”‚  TYPES D'EXPLICATIONS:                                     â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                     â”‚ â”‚
â”‚                                                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚                                                      â”‚ â”‚
â”‚  â”‚  1. EXPLICATIONS GLOBALES                           â”‚ â”‚
â”‚  â”‚     "Comment le modÃ¨le fonctionne gÃ©nÃ©ralement?"    â”‚ â”‚
â”‚  â”‚                                                      â”‚ â”‚
â”‚  â”‚     Importance Features (globale)                   â”‚ â”‚
â”‚  â”‚     Ã‚ge:       â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  (45%)             â”‚ â”‚
â”‚  â”‚     Revenu:    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ       (28%)             â”‚ â”‚
â”‚  â”‚     Lieu:      â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ             (15%)             â”‚ â”‚
â”‚  â”‚     Historique:â–ˆâ–ˆâ–ˆâ–ˆ              (12%)             â”‚ â”‚
â”‚  â”‚                                                      â”‚ â”‚
â”‚  â”‚  2. EXPLICATIONS LOCALES                            â”‚ â”‚
â”‚  â”‚     "Pourquoi le modÃ¨le a fait CETTE prÃ©diction?"   â”‚ â”‚
â”‚  â”‚                                                      â”‚ â”‚
â”‚  â”‚     PrÃ©diction: REFUSÃ‰                              â”‚ â”‚
â”‚  â”‚                                                      â”‚ â”‚
â”‚  â”‚     Facteurs contributifs pour CE cas:             â”‚ â”‚
â”‚  â”‚     Ã‚ge < 25:       â”€â”€â”€â”€â”€â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  (-0.34)            â”‚ â”‚
â”‚  â”‚     Revenu faible:  â”€â”€â”€â”€â”€â–ˆâ–ˆâ–ˆâ–ˆ   (-0.28)            â”‚ â”‚
â”‚  â”‚     Bon historique: â–ˆâ–ˆâ–ˆâ–ˆâ”€â”€â”€â”€â”€   (+0.21)            â”‚ â”‚
â”‚  â”‚                                                      â”‚ â”‚
â”‚  â”‚     "RefusÃ© principalement Ã  cause du jeune Ã¢ge    â”‚ â”‚
â”‚  â”‚      et faible revenu malgrÃ© bon historique"       â”‚ â”‚
â”‚  â”‚                                                      â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                            â”‚
â”‚                                                            â”‚
â”‚  TECHNIQUES XAI POPULAIRES:                                â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                â”‚
â”‚                                                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚                                                      â”‚ â”‚
â”‚  â”‚  SHAP (SHapley Additive exPlanations)               â”‚ â”‚
â”‚  â”‚  â€¢ Approche thÃ©orie des jeux                       â”‚ â”‚
â”‚  â”‚  â€¢ Attribue valeur contribution Ã  chaque feature   â”‚ â”‚
â”‚  â”‚  â€¢ CohÃ©rent: mÃªme entrÃ©e = mÃªme explication        â”‚ â”‚
â”‚  â”‚  â€¢ Fonctionne sur tout modÃ¨le (model-agnostic)     â”‚ â”‚
â”‚  â”‚                                                      â”‚ â”‚
â”‚  â”‚  LIME (Local Interpretable Model-agnostic Exp)      â”‚ â”‚
â”‚  â”‚  â€¢ CrÃ©e approximation linÃ©aire locale              â”‚ â”‚
â”‚  â”‚  â€¢ Perturbe entrÃ©e, observe changements            â”‚ â”‚
â”‚  â”‚  â€¢ Fit modÃ¨le simple autour prÃ©diction             â”‚ â”‚
â”‚  â”‚  â€¢ Bon pour explications image/texte               â”‚ â”‚
â”‚  â”‚                                                      â”‚ â”‚
â”‚  â”‚  VISUALISATION ATTENTION (pour transformers)        â”‚ â”‚
â”‚  â”‚  EntrÃ©e: "Le film Ã©tait absolument terrible"       â”‚ â”‚
â”‚  â”‚  Attention: Le film Ã©tait absolument terrible      â”‚ â”‚
â”‚  â”‚             â–‘   â–‘    â–‘      â–“â–“       â–ˆâ–ˆâ–ˆâ–ˆ          â”‚ â”‚
â”‚  â”‚  ModÃ¨le focalisÃ© sur "terrible" et "absolument"    â”‚ â”‚
â”‚  â”‚                                                      â”‚ â”‚
â”‚  â”‚  EXPLICATIONS CONTREFACTUELLES                      â”‚ â”‚
â”‚  â”‚  "Qu'est-ce qui devrait changer pour autre rÃ©sultat?"â”‚ â”‚
â”‚  â”‚  Actuel: PrÃªt REFUSÃ‰                               â”‚ â”‚
â”‚  â”‚  Contrefactuel: "Si le revenu Ã©tait â‚¬5000 plus    â”‚ â”‚
â”‚  â”‚  Ã©levÃ©, le prÃªt serait APPROUVÃ‰"                   â”‚ â”‚
â”‚  â”‚                                                      â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                            â”‚
â”‚                                                            â”‚
â”‚  EXIGENCES RÃ‰GLEMENTAIRES:                                 â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                 â”‚
â”‚                                                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚                                                      â”‚ â”‚
â”‚  â”‚  EU AI ACT (2024)                                   â”‚ â”‚
â”‚  â”‚  â”œâ”€ IA haut-risque doit Ãªtre comprÃ©hensible       â”‚ â”‚
â”‚  â”‚  â”œâ”€ Utilisateurs doivent pouvoir interprÃ©ter sortiesâ”‚ â”‚
â”‚  â”‚  â””â”€ Documentation comportement modÃ¨le requise      â”‚ â”‚
â”‚  â”‚                                                      â”‚ â”‚
â”‚  â”‚  RGPD Article 22                                    â”‚ â”‚
â”‚  â”‚  â”œâ”€ Droit Ã  explication dÃ©cisions automatisÃ©es    â”‚ â”‚
â”‚  â”‚  â””â”€ "Info significative sur logique impliquÃ©e"    â”‚ â”‚
â”‚  â”‚                                                      â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Questions frÃ©quentes

**Q: Quelle diffÃ©rence entre explicabilitÃ© et interprÃ©tabilitÃ©?**

R: Souvent utilisÃ©s de faÃ§on interchangeable. Techniquement: interprÃ©tabilitÃ© = Ã  quel point un modÃ¨le est comprÃ©hensible intrinsÃ¨quement; explicabilitÃ© = mÃ©thodes pour expliquer le comportement de tout modÃ¨le.

**Q: Les explications ralentissent-elles l'infÃ©rence?**

R: Les explications post-hoc (SHAP, LIME) ajoutent du calcul. Vous pouvez calculer les explications hors ligne pour l'analyse, ou utiliser des mÃ©thodes approximatives.

**Q: Les poids d'attention sont-ils des explications fiables?**

R: ControversÃ©. L'attention montre oÃ¹ le modÃ¨le a "regardÃ©," mais ne prouve pas la causalitÃ©.

## Termes associÃ©s

- AI Act â€” rÃ©glementation UE exigeant explicabilitÃ©
- ModÃ¨le boÃ®te noire â€” modÃ¨les nÃ©cessitant techniques XAI

---

## RÃ©fÃ©rences

> Lundberg & Lee (2017), "[A Unified Approach to Interpreting Model Predictions](https://arxiv.org/abs/1705.07874)", NeurIPS. [MÃ©thodologie SHAP]

> Ribeiro et al. (2016), "[Why Should I Trust You? Explaining Predictions](https://arxiv.org/abs/1602.04938)", KDD. [MÃ©thodologie LIME]

> Rudin (2019), "[Stop Explaining Black Box ML Models for High Stakes Decisions](https://arxiv.org/abs/1811.10154)", Nature Machine Intelligence.

> Commission EuropÃ©enne (2024), "[AI Act](https://eur-lex.europa.eu/eli/reg/2024/1689/oj)", Journal Officiel.

## References

> Lundberg & Lee (2017), "[A Unified Approach to Interpreting Model Predictions](https://arxiv.org/abs/1705.07874)", NeurIPS. [SHAP methodology]

> Ribeiro et al. (2016), "[Why Should I Trust You? Explaining the Predictions of Any Classifier](https://arxiv.org/abs/1602.04938)", KDD. [LIME methodology]

> Rudin (2019), "[Stop Explaining Black Box Machine Learning Models for High Stakes Decisions](https://arxiv.org/abs/1811.10154)", Nature Machine Intelligence. [Case for inherent interpretability]

> European Commission (2024), "[AI Act](https://eur-lex.europa.eu/eli/reg/2024/1689/oj)", Official Journal. [Regulatory requirements for explainability]
