---
term: "Uitlegbaarheid"
termSlug: "explainability"
short: "Het vermogen om te begrijpen, interpreteren en uitleggen hoe AI/ML-modellen voorspellingen makenâ€”essentieel voor vertrouwen, debugging, regelgevingscompliance en verantwoorde AI-inzet."
category: "ai-ml"
category_name: "AI & Machine Learning"
related: ["interpretability", "transparency", "black-box", "xai", "feature-importance", "ai-act"]
synonyms: ["Interpreteerbaarheid", "XAI", "Verklaarbare AI", "Modeltransparantie"]
locale: "nl"
draft: false
---

## Definitie

Uitlegbaarheid (of Explainable AI/XAI) verwijst naar technieken die AI-modelbeslissingen begrijpelijk maken voor mensen. Het beantwoordt "waarom maakte het model deze [voorspelling](/nl/glossary/inference/)?" in plaats van alleen "wat voorspelde het model?" [Uitlegbaarheid](/nl/glossary/algorithmic-transparency/) bestaat op een spectrum: van inherent interpreteerbare modellen (lineaire regressie, beslisbomen) tot post-hoc verklaringen voor black-box modellen (SHAP, LIME, attentievisualisatie). Naarmate AI-systemen steeds belangrijkere beslissingen nemen (gezondheidszorg, financiÃ«n, juridisch), wordt uitlegbaarheid cruciaal voor vertrouwen, verantwoording, debugging en regelgevingscompliance ([AI Act](/nl/glossary/eu-ai-act/), AVG Artikel 22).

## Waarom het belangrijk is

Uitlegbaarheid adresseert kritieke AI-implementatiebehoeften:

- **Vertrouwen** â€” gebruikers vertrouwen systemen die ze begrijpen
- **Debugging** â€” identificeren waarom modellen falen in specifieke gevallen
- **Regelgevingscompliance** â€” AI Act vereist uitleg voor hoog-risico AI
- **Biasdetectie** â€” onthullen of modellen beschermde attributen gebruiken
- **Domeinvalidatie** â€” experts verifiÃ«ren dat modelredenering klopt
- **Juridische verdedigbaarheid** â€” geautomatiseerde beslissingen uitleggen

## Hoe het werkt

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     UITLEGBAARHEID                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                            â”‚
â”‚  HET UITLEGBAARHEID SPECTRUM:                              â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                              â”‚
â”‚                                                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚                                                      â”‚ â”‚
â”‚  â”‚    INTERPRETEERBAAR         â†’          BLACK-BOX    â”‚ â”‚
â”‚  â”‚    (ingebouwd)                       (heeft XAI nodig)â”‚ â”‚
â”‚  â”‚                                                      â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”‚
â”‚  â”‚  â”‚   LINEAIRE  â”‚  â”‚   RANDOM    â”‚  â”‚   DIEP      â”‚ â”‚ â”‚
â”‚  â”‚  â”‚  REGRESSIE  â”‚  â”‚   FOREST    â”‚  â”‚  NEURAAL    â”‚ â”‚ â”‚
â”‚  â”‚  â”‚             â”‚  â”‚             â”‚  â”‚  NETWERK    â”‚ â”‚ â”‚
â”‚  â”‚  â”‚ coÃ«fficiÃ«nt â”‚  â”‚ feature     â”‚  â”‚             â”‚ â”‚ â”‚
â”‚  â”‚  â”‚ = directe   â”‚  â”‚ importance  â”‚  â”‚ ğŸ¤· ???     â”‚ â”‚ â”‚
â”‚  â”‚  â”‚ uitleg      â”‚  â”‚ beschikbaar â”‚  â”‚ Heeft SHAP  â”‚ â”‚ â”‚
â”‚  â”‚  â”‚             â”‚  â”‚             â”‚  â”‚ LIME nodig  â”‚ â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚
â”‚  â”‚                                                      â”‚ â”‚
â”‚  â”‚  â—„â”€â”€â”€ Meer interpreteerbaar  Minder interpr. â”€â”€â”€â–º   â”‚ â”‚
â”‚  â”‚  â—„â”€â”€â”€ Minder krachtig        Krachtiger â”€â”€â”€â–º        â”‚ â”‚
â”‚  â”‚                                                      â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                            â”‚
â”‚                                                            â”‚
â”‚  SOORTEN UITLEG:                                           â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                           â”‚
â”‚                                                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚                                                      â”‚ â”‚
â”‚  â”‚  1. GLOBALE UITLEG                                  â”‚ â”‚
â”‚  â”‚     "Hoe werkt het model over het algemeen?"        â”‚ â”‚
â”‚  â”‚                                                      â”‚ â”‚
â”‚  â”‚     Feature Importance (totaal)                     â”‚ â”‚
â”‚  â”‚     Leeftijd:  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  (45%)             â”‚ â”‚
â”‚  â”‚     Inkomen:   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ       (28%)             â”‚ â”‚
â”‚  â”‚     Locatie:   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ             (15%)             â”‚ â”‚
â”‚  â”‚     Historie:  â–ˆâ–ˆâ–ˆâ–ˆ              (12%)             â”‚ â”‚
â”‚  â”‚                                                      â”‚ â”‚
â”‚  â”‚  2. LOKALE UITLEG                                   â”‚ â”‚
â”‚  â”‚     "Waarom maakte het model DEZE voorspelling?"    â”‚ â”‚
â”‚  â”‚                                                      â”‚ â”‚
â”‚  â”‚     Voorspelling: AFGEWEZEN                         â”‚ â”‚
â”‚  â”‚                                                      â”‚ â”‚
â”‚  â”‚     Bijdragende factoren voor DIT geval:           â”‚ â”‚
â”‚  â”‚     Leeftijd < 25:  â”€â”€â”€â”€â”€â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  (-0.34)            â”‚ â”‚
â”‚  â”‚     Inkomen laag:   â”€â”€â”€â”€â”€â–ˆâ–ˆâ–ˆâ–ˆ   (-0.28)            â”‚ â”‚
â”‚  â”‚     Goede historie: â–ˆâ–ˆâ–ˆâ–ˆâ”€â”€â”€â”€â”€   (+0.21)            â”‚ â”‚
â”‚  â”‚                                                      â”‚ â”‚
â”‚  â”‚     "Afgewezen voornamelijk door jonge leeftijd    â”‚ â”‚
â”‚  â”‚      en laag inkomen ondanks goede historie"       â”‚ â”‚
â”‚  â”‚                                                      â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                            â”‚
â”‚                                                            â”‚
â”‚  POPULAIRE XAI TECHNIEKEN:                                 â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                 â”‚
â”‚                                                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚                                                      â”‚ â”‚
â”‚  â”‚  SHAP (SHapley Additive exPlanations)               â”‚ â”‚
â”‚  â”‚  â€¢ Speltheoretische aanpak                          â”‚ â”‚
â”‚  â”‚  â€¢ Kent bijdragewaarde toe aan elk kenmerk          â”‚ â”‚
â”‚  â”‚  â€¢ Consistent: zelfde input = zelfde uitleg         â”‚ â”‚
â”‚  â”‚  â€¢ Werkt op elk model (model-agnostisch)            â”‚ â”‚
â”‚  â”‚                                                      â”‚ â”‚
â”‚  â”‚  LIME (Local Interpretable Model-agnostic Exp)      â”‚ â”‚
â”‚  â”‚  â€¢ CreÃ«ert lokale lineaire benadering              â”‚ â”‚
â”‚  â”‚  â€¢ Verstoort input, observeert veranderingen       â”‚ â”‚
â”‚  â”‚  â€¢ Fit simpel model rond voorspelling              â”‚ â”‚
â”‚  â”‚  â€¢ Goed voor beeld/tekst uitleg                    â”‚ â”‚
â”‚  â”‚                                                      â”‚ â”‚
â”‚  â”‚  ATTENTIE VISUALISATIE (voor transformers)          â”‚ â”‚
â”‚  â”‚  Input: "De film was absoluut verschrikkelijk"     â”‚ â”‚
â”‚  â”‚  Attentie: De film was absoluut verschrikkelijk    â”‚ â”‚
â”‚  â”‚            â–‘   â–‘   â–‘    â–“â–“      â–ˆâ–ˆâ–ˆâ–ˆ               â”‚ â”‚
â”‚  â”‚  Model focuste op "verschrikkelijk" en "absoluut"  â”‚ â”‚
â”‚  â”‚                                                      â”‚ â”‚
â”‚  â”‚  COUNTERFACTUAL UITLEG                              â”‚ â”‚
â”‚  â”‚  "Wat zou moeten veranderen voor andere uitkomst?" â”‚ â”‚
â”‚  â”‚  Huidig: Lening AFGEWEZEN                          â”‚ â”‚
â”‚  â”‚  Counterfactual: "Als inkomen â‚¬5000 hoger was,    â”‚ â”‚
â”‚  â”‚  zou lening GOEDGEKEURD worden"                    â”‚ â”‚
â”‚  â”‚                                                      â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                            â”‚
â”‚                                                            â”‚
â”‚  WETTELIJKE VEREISTEN:                                     â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                     â”‚
â”‚                                                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚                                                      â”‚ â”‚
â”‚  â”‚  EU AI ACT (2024)                                   â”‚ â”‚
â”‚  â”‚  â”œâ”€ Hoog-risico AI moet begrijpelijk zijn          â”‚ â”‚
â”‚  â”‚  â”œâ”€ Gebruikers moeten outputs kunnen interpreteren â”‚ â”‚
â”‚  â”‚  â””â”€ Documentatie van modelgedrag vereist           â”‚ â”‚
â”‚  â”‚                                                      â”‚ â”‚
â”‚  â”‚  AVG Artikel 22                                     â”‚ â”‚
â”‚  â”‚  â”œâ”€ Recht op uitleg voor geautomatiseerde besluitenâ”‚ â”‚
â”‚  â”‚  â””â”€ "Betekenisvolle info over logica betrokken"   â”‚ â”‚
â”‚  â”‚                                                      â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Veelgestelde vragen

**V: Wat is het verschil tussen uitlegbaarheid en interpreteerbaarheid?**

A: Vaak door elkaar gebruikt. Technisch: interpreteerbaarheid = hoe begrijpelijk een model inherent is; uitlegbaarheid = methodes om elk modelgedrag uit te leggen. Een beslisboom is interpreteerbaar; een neuraal netwerk kan uitlegbaar worden gemaakt via SHAP.

**V: Vertragen uitleg de inferentie?**

A: Post-hoc uitleg (SHAP, LIME) voegen berekening toe. Je kunt uitleg offline berekenen voor analyse, of benaderingsmethodes gebruiken voor realtime.

**V: Zijn attentie-gewichten betrouwbare uitleg?**

A: Controversieel. Attentie toont waar het model "keek," maar bewijst geen causaliteit. Onderzoek toont dat attentie gemanipuleerd kan worden zonder voorspellingen te veranderen.

## Gerelateerde termen

- AI Act â€” EU-regelgeving die uitlegbaarheid vereist
- Black-box model â€” modellen die XAI-technieken nodig hebben

---

## Referenties

> Lundberg & Lee (2017), "[A Unified Approach to Interpreting Model Predictions](https://arxiv.org/abs/1705.07874)", NeurIPS. [SHAP-methodologie]

> Ribeiro et al. (2016), "[Why Should I Trust You? Explaining Predictions of Any Classifier](https://arxiv.org/abs/1602.04938)", KDD. [LIME-methodologie]

> Rudin (2019), "[Stop Explaining Black Box ML Models for High Stakes Decisions](https://arxiv.org/abs/1811.10154)", Nature Machine Intelligence.

> Europese Commissie (2024), "[AI Act](https://eur-lex.europa.eu/eli/reg/2024/1689/oj)", Official Journal.

## References

> Lundberg & Lee (2017), "[A Unified Approach to Interpreting Model Predictions](https://arxiv.org/abs/1705.07874)", NeurIPS. [SHAP methodology]

> Ribeiro et al. (2016), "[Why Should I Trust You? Explaining the Predictions of Any Classifier](https://arxiv.org/abs/1602.04938)", KDD. [LIME methodology]

> Rudin (2019), "[Stop Explaining Black Box Machine Learning Models for High Stakes Decisions](https://arxiv.org/abs/1811.10154)", Nature Machine Intelligence. [Case for inherent interpretability]

> European Commission (2024), "[AI Act](https://eur-lex.europa.eu/eli/reg/2024/1689/oj)", Official Journal. [Regulatory requirements for explainability]
