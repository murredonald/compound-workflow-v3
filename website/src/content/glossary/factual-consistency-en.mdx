---
term: "Factual consistency"
termSlug: "factual-consistency"
short: "The degree to which a generated answer agrees with trusted sources or ground truth."
category: "ai-ml"
category_name: "AI & Machine Learning"
related: ["ground-truth", "hallucination-rate", "answer-grounding"]
synonyms: ["Fact consistency", "Source consistency"]
locale: "en"
draft: false
---

## Definition

Factual consistency evaluates whether statements in a modelâ€™s output faithfully match the referenced documents, data, or [ground truth](/en/glossary/ground-truth/) labels.

## References

> Jiaxin Zhang et al. (2023), "[SAC3: Reliable Hallucination Detection in Black-Box Language Models via Semantic-aware Cross-check Consistency](https://arxiv.org/abs/2311.01740)", Conference on Empirical Methods in Natural Language Processing.

> Yixin Liu et al. (2022), "[On Improving Summarization Factual Consistency from Natural Language Feedback](https://arxiv.org/abs/2212.09968)", Annual Meeting of the Association for Computational Linguistics.

> Joy Mahapatra et al. (2024), "[An Extensive Evaluation of Factual Consistency in Large Language Models for Data-to-Text Generation](https://arxiv.org/abs/2411.19203)", arXiv.
