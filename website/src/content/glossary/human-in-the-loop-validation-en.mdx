---
term: "Human-in-the-loop validation"
termSlug: "human-in-the-loop-validation"
short: "Using human reviewers to check, correct, or approve AI outputs as part of an evaluation process."
category: "ai-ml"
category_name: "AI & Machine Learning"
related: ["evals-framework", "adversarial-testing", "audit-trail"]
synonyms: ["HITL validation", "Human review loop"]
locale: "en"
draft: false
---

## Definition

[Human-in-the-loop](/en/glossary/human-oversight/) validation incorporates expert or user feedback into evaluation, ensuring that AI outputs are checked and corrected before being trusted in high-stakes settings.

## References

> Andreas Holzinger (2016), "[Interactive machine learning for health informatics: when do we need the human-in-the-loop?](https://doi.org/10.1007/s40708-016-0042-6)", Brain Informatics.

> Eduardo Mosqueira-Rey et al. (2022), "[Human-in-the-loop machine learning: a state of the art](https://doi.org/10.1007/s10462-022-10246-w)", Artificial Intelligence Review.

> A. Gilad Kusne et al. (2020), "[On-the-fly closed-loop materials discovery via Bayesian active learning](https://doi.org/10.1038/s41467-020-19597-w)", Nature Communications.
