---
term: "Model robustness"
termSlug: "model-robustness"
short: "How well a model maintains performance under noise, shifts, or adversarial inputs."
category: "ai-ml"
category_name: "AI & Machine Learning"
related: ["adversarial-testing", "model-drift", "uncertainty-estimation"]
synonyms: ["Robustness", "Model resilience"]
locale: "en"
draft: false
---

## Definition

Model robustness captures a modelâ€™s stability when conditions change, such as new data distributions, perturbations, or attacks.

## References

> Yinpeng Dong et al. (2018), "[Boosting Adversarial Attacks with Momentum](https://doi.org/10.1109/cvpr.2018.00957)", .

> Jiawei Su et al. (2019), "[One Pixel Attack for Fooling Deep Neural Networks](https://doi.org/10.1109/tevc.2019.2890858)", IEEE Transactions on Evolutionary Computation.

> Kimin Lee et al. (2018), "[A Simple Unified Framework for Detecting Out-of-Distribution Samples and Adversarial Attacks](https://doi.org/10.48550/arxiv.1807.03888)", arXiv.
