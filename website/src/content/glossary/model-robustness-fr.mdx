---
term: "Robustesse du modèle"
termSlug: "model-robustness"
short: "Capacité d’un modèle à maintenir ses performances malgré le bruit, les dérives ou des entrées adversariales."
category: "ai-ml"
category_name: "IA & Machine Learning"
related: ["adversarial-testing", "model-drift", "uncertainty-estimation"]
synonyms: ["Robustesse", "Résilience du modèle"]
locale: "fr"
draft: false
---

## References

> Yinpeng Dong et al. (2018), "[Boosting Adversarial Attacks with Momentum](https://doi.org/10.1109/cvpr.2018.00957)", .

> Jiawei Su et al. (2019), "[One Pixel Attack for Fooling Deep Neural Networks](https://doi.org/10.1109/tevc.2019.2890858)", IEEE Transactions on Evolutionary Computation.

> Kimin Lee et al. (2018), "[A Simple Unified Framework for Detecting Out-of-Distribution Samples and Adversarial Attacks](https://doi.org/10.48550/arxiv.1807.03888)", arXiv.
