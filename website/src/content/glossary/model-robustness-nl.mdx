---
term: "Modelrobuustheid"
termSlug: "model-robustness"
short: "In welke mate een model prestaties behoudt bij ruis, verschuivingen of adversariÃ«le input."
category: "ai-ml"
category_name: "AI & Machine Learning"
related: ["adversarial-testing", "model-drift", "uncertainty-estimation"]
synonyms: ["Robuustheid", "Modelresistentie"]
locale: "nl"
draft: false
---

## References

> Yinpeng Dong et al. (2018), "[Boosting Adversarial Attacks with Momentum](https://doi.org/10.1109/cvpr.2018.00957)", .

> Jiawei Su et al. (2019), "[One Pixel Attack for Fooling Deep Neural Networks](https://doi.org/10.1109/tevc.2019.2890858)", IEEE Transactions on Evolutionary Computation.

> Kimin Lee et al. (2018), "[A Simple Unified Framework for Detecting Out-of-Distribution Samples and Adversarial Attacks](https://doi.org/10.48550/arxiv.1807.03888)", arXiv.
