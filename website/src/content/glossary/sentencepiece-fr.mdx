---
term: "SentencePiece"
termSlug: "sentencepiece"
short: "Une bibliothèque de tokenisation en sous-mots, indépendante de la langue, qui apprend un vocabulaire directement à partir du texte brut."
category: "ai-ml"
category_name: "IA & Machine Learning"
related: []
synonyms: []
locale: "fr"
draft: false
---

## Définition

SentencePiece est un tokenizer open source qui traite l'entrée comme un flux brut de bytes ou d'Unicode et apprend un vocabulaire de sous-mots (par exemple BPE ou unigram) sans règles de pré-[tokenisation](/fr/glossary/tokenization/) spécifiques à une langue.

## References

- Kudo & Richardson (2018), "[SentencePiece: A simple and language independent subword tokenizer and detokenizer for Neural Text Processing](https://doi.org/10.18653/v1/D18-2012)", EMNLP.

- Kudo (2018), "[Subword Regularization: Improving Neural Network Translation Models with Multiple Subword Candidates](https://doi.org/10.18653/v1/P18-1007)", ACL.

- Sennrich et al. (2016), "[Neural Machine Translation of Rare Words with Subword Units](https://doi.org/10.18653/v1/P16-1162)", ACL.
