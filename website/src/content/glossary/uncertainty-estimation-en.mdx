---
term: "Uncertainty estimation"
termSlug: "uncertainty-estimation"
short: "Quantifying how uncertain a model is about its predictions or answers."
category: "ai-ml"
category_name: "AI & Machine Learning"
related: ["calibration", "confidence-interval", "reliability-metrics"]
synonyms: ["Uncertainty quantification", "UQ"]
locale: "en"
draft: false
---

## Definition

Uncertainty estimation produces measures—such as variances, confidence scores, or ensembles—that indicate when a model might be wrong or should defer to humans.

## References

- Gal & Ghahramani (2016), "[Dropout as a Bayesian Approximation: Representing Model Uncertainty in Deep Learning](https://arxiv.org/abs/1506.02142)", ICML.

- Lakshminarayanan et al. (2017), "[Simple and Scalable Predictive Uncertainty Estimation using Deep Ensembles](https://arxiv.org/abs/1612.01474)", NeurIPS.

- Loquercio et al. (2020), "[A General Framework for Uncertainty Estimation in Deep Learning](https://doi.org/10.1109/LRA.2020.2974682)", IEEE Robotics and Automation Letters.
